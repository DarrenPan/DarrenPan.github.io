<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="Good Good Study">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Good Good Study">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Good Good Study">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/"/>





  <title>Good Good Study</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Good Good Study</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/20/caffe/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/20/caffe/" itemprop="url">Caffe</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-20T10:41:48+08:00">
                2018-12-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Image-Classification-and-Filter-Visualization"><a href="#Image-Classification-and-Filter-Visualization" class="headerlink" title="Image Classification and Filter Visualization"></a><a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/00-classification.ipynb" target="_blank" rel="noopener">Image Classification and Filter Visualization</a></h2><p>Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.</p>
<p><strong><em>set CPU mode and load net for test</em></strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">caffe.set_mode_cpu()</span><br><span class="line"></span><br><span class="line">net = caffe.Net(model_def,      <span class="comment"># defines the structure of the model</span></span><br><span class="line">                model_weights,  <span class="comment"># contains the trained weights</span></span><br><span class="line">                caffe.TEST)     <span class="comment"># use test mode (e.g., don't perform dropout)</span></span><br></pre></td></tr></table></figure>
<p><strong><em>input preprocessing</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Set up input preprocessing. (We&apos;ll use Caffe&apos;s caffe.io.Transformer to do this, but this step is independent of other parts of Caffe, so any custom preprocessing code may be used).</span><br><span class="line"></span><br><span class="line">Our default CaffeNet is configured to take images in BGR format. Values are expected to start in the range [0, 255] and then have the mean ImageNet pixel value subtracted from them. In addition, the channel dimension is expected as the first (outermost) dimension.</span><br><span class="line"></span><br><span class="line">As matplotlib will load images with values in the range [0, 1] in RGB format with the channel as the innermost dimension, we are arranging for the needed transformations here.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create transformer for the input called 'data'</span></span><br><span class="line">transformer = caffe.io.Transformer(&#123;<span class="string">'data'</span>: net.blobs[<span class="string">'data'</span>].data.shape&#125;)</span><br><span class="line"></span><br><span class="line">transformer.set_transpose(<span class="string">'data'</span>, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))  <span class="comment"># move image channels to outermost dimension</span></span><br><span class="line">transformer.set_mean(<span class="string">'data'</span>, mu)            <span class="comment"># subtract the dataset-mean value in each channel</span></span><br><span class="line">transformer.set_raw_scale(<span class="string">'data'</span>, <span class="number">255</span>)      <span class="comment"># rescale from [0, 1] to [0, 255]</span></span><br><span class="line">transformer.set_channel_swap(<span class="string">'data'</span>, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>))  <span class="comment"># swap channels from RGB to BGR</span></span><br></pre></td></tr></table></figure>
<p><strong><em>set the size of the input</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set the size of the input (we can skip this if we're happy</span></span><br><span class="line"><span class="comment">#  with the default; we can also change it later, e.g., for different batch sizes)</span></span><br><span class="line">net.blobs[<span class="string">'data'</span>].reshape(<span class="number">50</span>,        <span class="comment"># batch size</span></span><br><span class="line">                          <span class="number">3</span>,         <span class="comment"># 3-channel (BGR) images</span></span><br><span class="line">                          <span class="number">227</span>, <span class="number">227</span>)  <span class="comment"># image size is 227x227</span></span><br></pre></td></tr></table></figure></p>
<p><strong><em>load an image and perform the preprocessing</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image = caffe.io.load_image(caffe_root + <span class="string">'examples/images/cat.jpg'</span>)</span><br><span class="line">transformed_image = transformer.preprocess(<span class="string">'data'</span>, image)</span><br></pre></td></tr></table></figure></p>
<p><strong><em>classify</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># copy the image data into the memory allocated for the net</span></span><br><span class="line">net.blobs[<span class="string">'data'</span>].data[...] = transformed_image</span><br><span class="line"></span><br><span class="line"><span class="comment">### perform classification</span></span><br><span class="line">output = net.forward()</span><br><span class="line"></span><br><span class="line">output_prob = output[<span class="string">'prob'</span>][<span class="number">0</span>]  <span class="comment"># the output probability vector for the first image in the batch</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">'predicted class is:'</span>, output_prob.argmax()</span><br></pre></td></tr></table></figure></p>
<p><strong><em>top5</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sort top five predictions from softmax output</span></span><br><span class="line">top_inds = output_prob.argsort()[::<span class="number">-1</span>][:<span class="number">5</span>]  <span class="comment"># reverse sort and take five largest items</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">'probabilities and labels:'</span></span><br><span class="line">zip(output_prob[top_inds], labels[top_inds])</span><br></pre></td></tr></table></figure></p>
<p><strong><em>switch to GPU</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">caffe.set_device(<span class="number">0</span>)  <span class="comment"># if we have multiple GPUs, pick the first one</span></span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line">net.forward()  <span class="comment"># run once before timing to set up memory</span></span><br></pre></td></tr></table></figure></p>
<p><strong><em>show the output shape of each layers</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> layer_name, blob <span class="keyword">in</span> net.blobs.iteritems():</span><br><span class="line">    <span class="keyword">print</span> layer_name + <span class="string">'\t'</span> + str(blob.data.shape)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">data	(50, 3, 227, 227)</span><br><span class="line">conv1	(50, 96, 55, 55)</span><br><span class="line">pool1	(50, 96, 27, 27)</span><br><span class="line">norm1	(50, 96, 27, 27)</span><br><span class="line">conv2	(50, 256, 27, 27)</span><br><span class="line">pool2	(50, 256, 13, 13)</span><br><span class="line">norm2	(50, 256, 13, 13)</span><br><span class="line">conv3	(50, 384, 13, 13)</span><br><span class="line">conv4	(50, 384, 13, 13)</span><br><span class="line">conv5	(50, 256, 13, 13)</span><br><span class="line">pool5	(50, 256, 6, 6)</span><br><span class="line">fc6		(50, 4096)</span><br><span class="line">fc7		(50, 4096)</span><br><span class="line">fc8		(50, 1000)</span><br><span class="line">prob	(50, 1000)</span><br></pre></td></tr></table></figure>
<p><strong><em>show the parameter shape</em></strong><br>We need to index the resulting values with either [0] for weights or [1] for biases.<br>The param shapes typically have the form <code>(output_channels, input_channels, filter_height, filter_width)</code>(for the weights) and the 1-dimensional shape <code>(output_channels,)</code>(for the biases).<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> layer_name, param <span class="keyword">in</span> net.params.iteritems():</span><br><span class="line">    <span class="keyword">print</span> layer_name + <span class="string">'\t'</span> + str(param[<span class="number">0</span>].data.shape), str(param[<span class="number">1</span>].data.shape)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">conv1	(96, 3, 11, 11) (96,)</span><br><span class="line">conv2	(256, 48, 5, 5) (256,)</span><br><span class="line">conv3	(384, 256, 3, 3) (384,)</span><br><span class="line">conv4	(384, 192, 3, 3) (384,)</span><br><span class="line">conv5	(256, 192, 3, 3) (256,)</span><br><span class="line">fc6	(4096, 9216) (4096,)</span><br><span class="line">fc7	(4096, 4096) (4096,)</span><br><span class="line">fc8	(1000, 4096) (1000,)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Learning-LeNet"><a href="#Learning-LeNet" class="headerlink" title="Learning LeNet"></a><a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/01-learning-lenet.ipynb" target="_blank" rel="noopener">Learning LeNet</a></h2><p>Define, train, and test the classic LeNet with the Python interface.</p>
<p><strong><em>create LeNet</em></strong></p>
<p>We’ll need two external files to help out:</p>
<ul>
<li>the net <code>prototxt</code>, defining the architecture and pointing to the train/test data</li>
<li>the solver <code>prototxt</code>, defining the learning parameters</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> caffe <span class="keyword">import</span> layers <span class="keyword">as</span> L, params <span class="keyword">as</span> P</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lenet</span><span class="params">(lmdb, batch_size)</span>:</span></span><br><span class="line">    <span class="comment"># our version of LeNet: a series of linear and simple nonlinear transformations</span></span><br><span class="line">    n = caffe.NetSpec()</span><br><span class="line">    </span><br><span class="line">    n.data, n.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,transform_param=dict(scale=<span class="number">1.</span>/<span class="number">255</span>), ntop=<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    n.conv1 = L.Convolution(n.data, kernel_size=<span class="number">5</span>, num_output=<span class="number">20</span>, weight_filler=dict(type=<span class="string">'xavier'</span>))</span><br><span class="line">    n.pool1 = L.Pooling(n.conv1, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, pool=P.Pooling.MAX)</span><br><span class="line">    n.conv2 = L.Convolution(n.pool1, kernel_size=<span class="number">5</span>, num_output=<span class="number">50</span>, weight_filler=dict(type=<span class="string">'xavier'</span>))</span><br><span class="line">    n.pool2 = L.Pooling(n.conv2, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, pool=P.Pooling.MAX)</span><br><span class="line">    n.fc1 =   L.InnerProduct(n.pool2, num_output=<span class="number">500</span>, weight_filler=dict(type=<span class="string">'xavier'</span>))</span><br><span class="line">    n.relu1 = L.ReLU(n.fc1, in_place=<span class="keyword">True</span>)</span><br><span class="line">    n.score = L.InnerProduct(n.relu1, num_output=<span class="number">10</span>, weight_filler=dict(type=<span class="string">'xavier'</span>))</span><br><span class="line">    n.loss =  L.SoftmaxWithLoss(n.score, n.label)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> n.to_proto()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'mnist/lenet_auto_train.prototxt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(str(lenet(<span class="string">'mnist/mnist_train_lmdb'</span>, <span class="number">64</span>)))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'mnist/lenet_auto_test.prototxt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(str(lenet(<span class="string">'mnist/mnist_test_lmdb'</span>, <span class="number">100</span>)))</span><br></pre></td></tr></table></figure>
<p>The net has been written to disk in a more verbose but human-readable serialization format using Google’s protobuf library. You can read, write, and modify this description directly. Let’s take a look at the train net. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"data"</span></span><br><span class="line">  type: <span class="string">"Data"</span></span><br><span class="line">  top: <span class="string">"data"</span></span><br><span class="line">  top: <span class="string">"label"</span></span><br><span class="line">  transform_param &#123;</span><br><span class="line">    scale: <span class="number">0.00392156862745</span></span><br><span class="line">  &#125;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    source: <span class="string">"mnist/mnist_train_lmdb"</span></span><br><span class="line">    batch_size: <span class="number">64</span></span><br><span class="line">    backend: LMDB</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv1"</span></span><br><span class="line">  type: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"data"</span></span><br><span class="line">  top: <span class="string">"conv1"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">20</span></span><br><span class="line">    kernel_size: <span class="number">5</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool1"</span></span><br><span class="line">  type: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"conv1"</span></span><br><span class="line">  top: <span class="string">"pool1"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: <span class="number">2</span></span><br><span class="line">    stride: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv2"</span></span><br><span class="line">  type: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"pool1"</span></span><br><span class="line">  top: <span class="string">"conv2"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">50</span></span><br><span class="line">    kernel_size: <span class="number">5</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool2"</span></span><br><span class="line">  type: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"conv2"</span></span><br><span class="line">  top: <span class="string">"pool2"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: <span class="number">2</span></span><br><span class="line">    stride: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"fc1"</span></span><br><span class="line">  type: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"pool2"</span></span><br><span class="line">  top: <span class="string">"fc1"</span></span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">500</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu1"</span></span><br><span class="line">  type: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"fc1"</span></span><br><span class="line">  top: <span class="string">"fc1"</span></span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"score"</span></span><br><span class="line">  type: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"fc1"</span></span><br><span class="line">  top: <span class="string">"score"</span></span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">10</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"loss"</span></span><br><span class="line">  type: <span class="string">"SoftmaxWithLoss"</span></span><br><span class="line">  bottom: <span class="string">"score"</span></span><br><span class="line">  bottom: <span class="string">"label"</span></span><br><span class="line">  top: <span class="string">"loss"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Now let’s see the learning parameters, which are also written as a <code>prototxt</code> file (already provided on disk). We’re using SGD with momentum, weight decay, and a specific learning rate schedule<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The train/test net protocol buffer definition</span></span><br><span class="line">train_net: <span class="string">"mnist/lenet_auto_train.prototxt"</span></span><br><span class="line">test_net: <span class="string">"mnist/lenet_auto_test.prototxt"</span></span><br><span class="line"><span class="comment"># test_iter specifies how many forward passes the test should carry out.</span></span><br><span class="line"><span class="comment"># In the case of MNIST, we have test batch size 100 and 100 test iterations,</span></span><br><span class="line"><span class="comment"># covering the full 10,000 testing images.</span></span><br><span class="line">test_iter: <span class="number">100</span></span><br><span class="line"><span class="comment"># Carry out testing every 500 training iterations.</span></span><br><span class="line">test_interval: <span class="number">500</span></span><br><span class="line"><span class="comment"># The base learning rate, momentum and the weight decay of the network.</span></span><br><span class="line">base_lr: <span class="number">0.01</span></span><br><span class="line">momentum: <span class="number">0.9</span></span><br><span class="line">weight_decay: <span class="number">0.0005</span></span><br><span class="line"><span class="comment"># The learning rate policy</span></span><br><span class="line">lr_policy: <span class="string">"inv"</span></span><br><span class="line">gamma: <span class="number">0.0001</span></span><br><span class="line">power: <span class="number">0.75</span></span><br><span class="line"><span class="comment"># Display every 100 iterations</span></span><br><span class="line">display: <span class="number">100</span></span><br><span class="line"><span class="comment"># The maximum number of iterations</span></span><br><span class="line">max_iter: <span class="number">10000</span></span><br><span class="line"><span class="comment"># snapshot intermediate results</span></span><br><span class="line">snapshot: <span class="number">5000</span></span><br><span class="line">snapshot_prefix: <span class="string">"mnist/lenet"</span></span><br></pre></td></tr></table></figure></p>
<p><strong><em>loading and checking the slover</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">caffe.set_device(<span class="number">0</span>)</span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line"></span><br><span class="line"><span class="comment">### load the solver and create train and test nets</span></span><br><span class="line">solver = <span class="keyword">None</span>  <span class="comment"># ignore this workaround for lmdb data (can't instantiate two solvers on the same data)</span></span><br><span class="line">solver = caffe.SGDSolver(<span class="string">'mnist/lenet_auto_solver.prototxt'</span>)</span><br></pre></td></tr></table></figure></p>
<p><em>check</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># each output is (batch size, feature dim, spatial dim)</span></span><br><span class="line">[(k, v.data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> solver.net.blobs.items()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># just print the weight sizes (we'll omit the biases)</span></span><br><span class="line">[(k, v[<span class="number">0</span>].data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> solver.net.params.items()]</span><br><span class="line">Out[<span class="number">9</span>]:</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">solver.net.forward()  <span class="comment"># train net</span></span><br><span class="line">solver.test_nets[<span class="number">0</span>].forward()  <span class="comment"># test net (there can be more than one)</span></span><br></pre></td></tr></table></figure>
<p><strong><em>Writing a custom training loop</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">niter = <span class="number">200</span></span><br><span class="line">test_interval = <span class="number">25</span></span><br><span class="line"><span class="comment"># losses will also be stored in the log</span></span><br><span class="line">train_loss = zeros(niter)</span><br><span class="line">test_acc = zeros(int(np.ceil(niter / test_interval)))</span><br><span class="line">output = zeros((niter, <span class="number">8</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># the main solver loop</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(niter):</span><br><span class="line">    solver.step(<span class="number">1</span>)  <span class="comment"># SGD by Caffe</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store the train loss</span></span><br><span class="line">    train_loss[it] = solver.net.blobs[<span class="string">'loss'</span>].data</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store the output on the first test batch</span></span><br><span class="line">    <span class="comment"># (start the forward pass at conv1 to avoid loading new data)</span></span><br><span class="line">    solver.test_nets[<span class="number">0</span>].forward(start=<span class="string">'conv1'</span>)</span><br><span class="line">    output[it] = solver.test_nets[<span class="number">0</span>].blobs[<span class="string">'score'</span>].data[:<span class="number">8</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># run a full test every so often</span></span><br><span class="line">    <span class="comment"># (Caffe can also do this for us and write to a log, but we show here</span></span><br><span class="line">    <span class="comment">#  how to do it directly in Python, where more complicated things are easier.)</span></span><br><span class="line">    <span class="keyword">if</span> it % test_interval == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'Iteration'</span>, it, <span class="string">'testing...'</span></span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> test_it <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">            solver.test_nets[<span class="number">0</span>].forward()</span><br><span class="line">            correct += sum(solver.test_nets[<span class="number">0</span>].blobs[<span class="string">'score'</span>].data.argmax(<span class="number">1</span>)</span><br><span class="line">                           == solver.test_nets[<span class="number">0</span>].blobs[<span class="string">'label'</span>].data)</span><br><span class="line">        test_acc[it // test_interval] = correct / <span class="number">1e4</span></span><br></pre></td></tr></table></figure></p>
<p><strong><em>define slover</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> caffe.proto <span class="keyword">import</span> caffe_pb2</span><br><span class="line">s = caffe_pb2.SolverParameter()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set a seed for reproducible experiments:</span></span><br><span class="line"><span class="comment"># this controls for randomization in training.</span></span><br><span class="line">s.random_seed = <span class="number">0xCAFFE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify locations of the train and (maybe) test networks.</span></span><br><span class="line">s.train_net = train_net_path</span><br><span class="line">s.test_net.append(test_net_path)</span><br><span class="line">s.test_interval = <span class="number">500</span>  <span class="comment"># Test after every 500 training iterations.</span></span><br><span class="line">s.test_iter.append(<span class="number">100</span>) <span class="comment"># Test on 100 batches each time we test.</span></span><br><span class="line"></span><br><span class="line">s.max_iter = <span class="number">10000</span>     <span class="comment"># no. of times to update the net (training iterations)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># EDIT HERE to try different solvers</span></span><br><span class="line"><span class="comment"># solver types include "SGD", "Adam", and "Nesterov" among others.</span></span><br><span class="line">s.type = <span class="string">"SGD"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the initial learning rate for SGD.</span></span><br><span class="line">s.base_lr = <span class="number">0.01</span>  <span class="comment"># EDIT HERE to try different learning rates</span></span><br><span class="line"><span class="comment"># Set momentum to accelerate learning by</span></span><br><span class="line"><span class="comment"># taking weighted average of current and previous updates.</span></span><br><span class="line">s.momentum = <span class="number">0.9</span></span><br><span class="line"><span class="comment"># Set weight decay to regularize and prevent overfitting</span></span><br><span class="line">s.weight_decay = <span class="number">5e-4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set `lr_policy` to define how the learning rate changes during training.</span></span><br><span class="line"><span class="comment"># This is the same policy as our default LeNet.</span></span><br><span class="line">s.lr_policy = <span class="string">'inv'</span></span><br><span class="line">s.gamma = <span class="number">0.0001</span></span><br><span class="line">s.power = <span class="number">0.75</span></span><br><span class="line"><span class="comment"># EDIT HERE to try the fixed rate (and compare with adaptive solvers)</span></span><br><span class="line"><span class="comment"># `fixed` is the simplest policy that keeps the learning rate constant.</span></span><br><span class="line"><span class="comment"># s.lr_policy = 'fixed'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the current training loss and accuracy every 1000 iterations.</span></span><br><span class="line">s.display = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Snapshots are files used to store networks we've trained.</span></span><br><span class="line"><span class="comment"># We'll snapshot every 5K iterations -- twice during training.</span></span><br><span class="line">s.snapshot = <span class="number">5000</span></span><br><span class="line">s.snapshot_prefix = <span class="string">'mnist/custom_net'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train on the GPU</span></span><br><span class="line">s.solver_mode = caffe_pb2.SolverParameter.GPU</span><br><span class="line"></span><br><span class="line"><span class="comment"># Write the solver to a temporary file and return its filename.</span></span><br><span class="line"><span class="keyword">with</span> open(solver_config_path, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(str(s))</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="Fine-tuning-for-Style-Recognition"><a href="#Fine-tuning-for-Style-Recognition" class="headerlink" title="Fine-tuning for Style Recognition"></a><a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/02-fine-tuning.ipynb" target="_blank" rel="noopener">Fine-tuning for Style Recognition</a></h2><p>Fine-tune the ImageNet-trained CaffeNet on new data.</p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/14/network_structure_experience/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/14/network_structure_experience/" itemprop="url">Experience in Network Structure</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-14T14:36:12+08:00">
                2018-12-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Improvement-for-Feature-Expression"><a href="#Improvement-for-Feature-Expression" class="headerlink" title="Improvement for Feature Expression"></a>Improvement for Feature Expression</h1><h2 id="inverted-residual-with-linear-bottleneck"><a href="#inverted-residual-with-linear-bottleneck" class="headerlink" title="inverted residual with linear bottleneck"></a>inverted residual with linear bottleneck</h2><h2 id="ReLU6-、-ReLU、PReLU"><a href="#ReLU6-、-ReLU、PReLU" class="headerlink" title="ReLU6 、 ReLU、PReLU"></a>ReLU6 、 ReLU、PReLU</h2><h1 id="Acceleration-and-Compression"><a href="#Acceleration-and-Compression" class="headerlink" title="Acceleration and Compression"></a>Acceleration and Compression</h1><h2 id="Depthwise-Separable-Convolution"><a href="#Depthwise-Separable-Convolution" class="headerlink" title="Depthwise Separable Convolution"></a>Depthwise Separable Convolution</h2><p><img src="/2018/12/14/network_structure_experience/2.jpg" alt=""></p>
<p>computational cost reduce from </p>
<p><img src="/2018/12/14/network_structure_experience/3.jpg" alt=""></p>
<p>to</p>
<p><img src="/2018/12/14/network_structure_experience/4.jpg" alt=""></p>
<h2 id="Group-Convolution"><a href="#Group-Convolution" class="headerlink" title="Group Convolution"></a>Group Convolution</h2><h2 id="from-35x35x320-to-17x17x640"><a href="#from-35x35x320-to-17x17x640" class="headerlink" title="from 35x35x320 to 17x17x640:"></a>from 35x35x320 to 17x17x640:</h2><ol>
<li>conv+pooling or pooling + conv</li>
<li>conv with stride 2</li>
<li><img src="/2018/12/14/network_structure_experience/1.png" alt=""><br>remain to study which is faster between 2 and 3.</li>
</ol>
<h1 id="Inspired-Architecture"><a href="#Inspired-Architecture" class="headerlink" title="Inspired Architecture"></a>Inspired Architecture</h1><h1 id="Insight"><a href="#Insight" class="headerlink" title="Insight"></a>Insight</h1><p>Manifold of interest should lie in a low-dimensional subspace of the higher-dimensional activation space (non-linearity destroys information in low-dimensional space.)<br><img src="/2018/12/14/network_structure_experience/5.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/14/object_detection_paper_summarization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/14/object_detection_paper_summarization/" itemprop="url">Object Detection Paper Summarization</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-14T14:36:12+08:00">
                2018-12-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Basic-Detection-Framework"><a href="#Basic-Detection-Framework" class="headerlink" title="Basic Detection Framework"></a>Basic Detection Framework</h1><h2 id="Two-stage："><a href="#Two-stage：" class="headerlink" title="Two stage："></a>Two stage：</h2><p><strong>[R-CNN]</strong><br><strong>[SPP-Net]</strong><br><strong>[Fast R-CNN]</strong><br><strong>[Faster R-CNN]</strong></p>
<h2 id="One-stage"><a href="#One-stage" class="headerlink" title="One stage:"></a>One stage:</h2><p><strong>[YOLO]</strong><br><strong>[SSD]</strong><br><strong>[YOLOv2]</strong><br><strong>[YOLOv3]</strong></p>
<h1 id="Improvement-for-Two-Stage-Framework"><a href="#Improvement-for-Two-Stage-Framework" class="headerlink" title="Improvement for Two Stage Framework"></a>Improvement for Two Stage Framework</h1><h2 id="To-alleviate-the-problems-arising-from-scale-variation-and-small-object-instances"><a href="#To-alleviate-the-problems-arising-from-scale-variation-and-small-object-instances" class="headerlink" title="To alleviate the problems arising from scale variation and small object instances"></a>To alleviate the problems arising from scale variation and small object instances</h2><p><img src="/2018/12/14/object_detection_paper_summarization/21.png" alt=""></p>
<h3 id="Construct-feature-pyramid"><a href="#Construct-feature-pyramid" class="headerlink" title="Construct feature pyramid"></a>Construct feature pyramid</h3><p><strong>[FPN - CVPR2017] Feature Pyramid Networks for Object Detection</strong><br>[paper] <a href="https://arxiv.org/abs/1612.03144" target="_blank" rel="noopener">https://arxiv.org/abs/1612.03144</a><br>[summarization]<br>-Difference with previous segmentation methods which use top-down and skip connections architecture: predictions are independently made on each level.<br><img src="/2018/12/14/object_detection_paper_summarization/22.png" alt=""><br>-The topdown pathway hallucinates higher resolution features by upsampling spatially coarser, but semantically stronger, feature maps from higher pyramid levels.<br>-Each lateral connection merges feature maps of the same spatial size from the bottom-up pathway and the top-down pathway.<br>-The bottom-up feature map is of lower-level semantics, but its activations are more accurately localized as it was subsampled fewer times.<br><img src="/2018/12/14/object_detection_paper_summarization/23.png" alt=""></p>
<p><strong>[TDM - CVPR2017] Beyond Skip Connections: Top-Down Modulation for Object Detection</strong><br><img src="/2018/12/14/object_detection_paper_summarization/24.png" alt=""><br><img src="/2018/12/14/object_detection_paper_summarization/25.png" alt=""></p>
<h3 id="Multi-scale-training-approach-image-pyramid"><a href="#Multi-scale-training-approach-image-pyramid" class="headerlink" title="Multi-scale training approach (image pyramid)"></a>Multi-scale training approach (image pyramid)</h3><p><strong>[SNIP - CVPR2018] An Analysis of Scale Invariance in Object Detection – SNIP</strong><br>[paper] <a href="https://arxiv.org/abs/1711.08189" target="_blank" rel="noopener">https://arxiv.org/abs/1711.08189</a><br>[summarization]<br>-Scale Normalization for Image Pyramids</p>
<p>-Use Image Pyramids, for each image(with multi-scale), training is only performed on objects that fall in the desired scale range and the remainder are simply ignored during back-propagation </p>
<p>-Deformable R-FCN + Soft-NMS ResNet-101/DPN-98      -&gt; 48.3mAP<br><img src="/2018/12/14/object_detection_paper_summarization/3.png" alt=""></p>
<p><strong>[SNIPER - NIPS2018] SNIPER: Efficient Multi-Scale Training</strong><br>[paper] <a href="https://arxiv.org/abs/1805.09300" target="_blank" rel="noopener">https://arxiv.org/abs/1805.09300</a><br>[official code] <a href="https://github.com/mahyarnajibi/SNIPER" target="_blank" rel="noopener">https://github.com/mahyarnajibi/SNIPER</a><br>[summarization]<br>-Chip Generation: For each scale, KxK pixels chips are placed at equal intervals of d pixels</p>
<p>-Positive Chip Selection: A ground-truth box is said to be covered if it is completely enclosed inside a chip. Ground-truth instances which have a partial overlap (IoU &gt; 0) with a chip are cropped. All the cropped ground-truth boxes (valid or invalid) are retained in the chip<br><img src="/2018/12/14/object_detection_paper_summarization/4.png" alt=""></p>
<p>-Negative Chip Selection:First train RPN for a couple of epochs. Then, for each scale i, we greedily select all the chips which cover at least M proposals.<br><img src="/2018/12/14/object_detection_paper_summarization/5.png" alt=""></p>
<h2 id="To-improve-localization-accuracy"><a href="#To-improve-localization-accuracy" class="headerlink" title="To improve localization accuracy"></a>To improve localization accuracy</h2><h3 id="Improve-bounding-box-refinement-method"><a href="#Improve-bounding-box-refinement-method" class="headerlink" title="Improve bounding box refinement method"></a>Improve bounding box refinement method</h3><p>Previous method: Using iterative bounding box regression to refine a bounding box.<br>This idea  ignores two problems:<br>(1) a regressor trained at low IoU threshhold (such as 0.5, used to defind postives/negetives) is suboptimal for proposals of higher IoUs.<br>(2) the distribution of bounding boxes changes significantly after each iteration.<br>Usually, there is no benefit beyond applying the same regressoin function twice.</p>
<p><strong>[Cascade R-CNN]</strong></p>
<p><strong>[IoU-Net]</strong> </p>
<h3 id="Predict-localization-confidence"><a href="#Predict-localization-confidence" class="headerlink" title="Predict localization confidence"></a>Predict localization confidence</h3><p>-Two drawbacks without localization confidence:<br>(1)  In nms, the classification scores are typically used as the metric for ranking the proposals. But the localization accuracy is not well correlated with the classification confidence.<br>(2) The absence of localization confidence makes the widely adopted bounding box regression less interpretable. Bounding box regression may degenerate the localization of input bounding boxes if applied for multiple times</p>
<p><strong>[IoU-Net ECCV2018] Acquisition of Localization Confidence for Accurate Object Detection</strong><br>[paper] <a href="https://arxiv.org/abs/1807.11590" target="_blank" rel="noopener">https://arxiv.org/abs/1807.11590</a><br>[official code] <a href="https://github.com/vacancy/PreciseRoIPooling" target="_blank" rel="noopener">https://github.com/vacancy/PreciseRoIPooling</a> (PreciseRoIPooling)<br>[summarization]<br>-Introduce <em>IoU-Net</em>, which predicts the IoU between detected bounding boxes and their corresponding ground-truth boxes, making the networks aware of the localization criterion.</p>
<p>-Generate bounding boxes and labels for training the IoU-Net by augmenting the ground-truth, instead of taking proposals from RPNs.<br><img src="/2018/12/14/object_detection_paper_summarization/11.png" alt=""></p>
<p>-<strong><em>IoU-guided NMS</em></strong>: Replace classification confidence with the predicted IoU as the ranking keyword in NMS. When a box i eliminates box j, update the classification confidence si of box i by si = max(si; sj )</p>
<p>-<strong><em>New bounding box refinement method</em></strong>:  Optimization-based bounding box refinement (on par with traditional regression-based methods.)<br><img src="/2018/12/14/object_detection_paper_summarization/13.png" alt=""></p>
<p>-Precise RoI Pooling: It avoids any quantization of coordinates and has a continuous gradient on bounding box coordinates.<br><img src="/2018/12/14/object_detection_paper_summarization/12.png" alt=""></p>
<h2 id="To-remove-duplicated-bounding-boxes"><a href="#To-remove-duplicated-bounding-boxes" class="headerlink" title="To remove duplicated bounding boxes"></a>To remove duplicated bounding boxes</h2><p>Widely-adopted approach: NMS</p>
<h3 id="Modification-for-NMS"><a href="#Modification-for-NMS" class="headerlink" title="Modification for NMS"></a>Modification for NMS</h3><h2 id="To-eliminate-high-scored-false-positives"><a href="#To-eliminate-high-scored-false-positives" class="headerlink" title="To eliminate high-scored false positives"></a>To eliminate high-scored false positives</h2><p><img src="/2018/12/14/object_detection_paper_summarization/14.png" alt=""></p>
<h3 id="Learning-high-quality-object-detectors"><a href="#Learning-high-quality-object-detectors" class="headerlink" title="Learning high quality object detectors"></a>Learning high quality object detectors</h3><p>-IoU threshhold(u): is set to determine positives/negetives</p>
<p>When u is high, the positives contain less background, but it is difficult to assemble enough positive training examples. When u is low, a richer and more diversified positive training set is available, but the trained detector has little incentive to reject close false positives.In general, it is very difficult to ask a single classifier to perform uniformly well over all IoU levels.</p>
<p>低IoU threshold对于低IoU的样本有更好的改善，但是对于高IoU的样本就不如高threshold的有用。原因在于不同threshold下样本的分布会不一致，也就导致同一个threshold很难对所有样本都有效。<br><img src="/2018/12/14/object_detection_paper_summarization/15.png" alt=""></p>
<p><strong>[Cascade RCNN - CVPR2018] Cascade R-CNN: Delving into High Quality Object Detection</strong><br>[paper] <a href="https://arxiv.org/abs/1712.00726" target="_blank" rel="noopener">https://arxiv.org/abs/1712.00726</a><br>[official code] <a href="https://github.com/zhaoweicai/cascade-rcnn" target="_blank" rel="noopener">https://github.com/zhaoweicai/cascade-rcnn</a><br>[summarization]<br><img src="/2018/12/14/object_detection_paper_summarization/16.png" alt=""><br>-At each stage t, the R-CNN includes a classifier ht and a regressor ft optimized for IoU threshold ut, where ut &gt; ut−1. This is guaranteed by minimizing the loss</p>
<p><img src="/2018/12/14/object_detection_paper_summarization/17.png" alt=""><br>-Cascaded regression is a resampling procedure that changes the distribution of hypotheses to be processed by the different stages. By adjusting bounding boxes, each stage aims to find a good set of close false positives for training the next stage</p>
<p>-A bounding box regressor trained for a certain u tends to produce bounding boxes of higher IoU. Hence, starting from a set of examples (xi, bi), cascade regression successively resamples an example distribution (x′i, b′i) of higher IoU.<br><img src="/2018/12/14/object_detection_paper_summarization/18.png" alt=""></p>
<h3 id="Improve-the-classification-power"><a href="#Improve-the-classification-power" class="headerlink" title="Improve the classification power"></a>Improve the classification power</h3><p>(1)Shared feature representation for both classification and localization may not be optimal</p>
<p>(2)joint optimization also leads to possible sub-optimal to balance the goals of multiple tasks and could not directly utilize the full potential on individual tasks;</p>
<p>(3)large receptive fields could lead to inferior classification capacity by introducing redundant context information for small objects.</p>
<p><strong>[DCR - ECCV2018] Revisiting RCNN: On Awakening the Classification Power of Faster RCNN</strong><br>[paper] <a href="https://arxiv.org/abs/1803.06799" target="_blank" rel="noopener">https://arxiv.org/abs/1803.06799</a><br>[official code] <a href="https://github.com/bowenc0221/Decoupled-Classification-Refinement" target="_blank" rel="noopener">https://github.com/bowenc0221/Decoupled-Classification-Refinement</a><br>[summarization]<br>-Propose Decoupled Classification Refinement to eliminate high-scored false positives and improve the region proposal classification results.</p>
<p>-It takes input from a base classiffier, e.g. the Faster RCNN, and refine the classification results using a RCNN-styled network.</p>
<p>-Adaptive Receptive Field<br><img src="/2018/12/14/object_detection_paper_summarization/1.jpg" alt=""></p>
<p><strong>[DCR V2]  Decoupled Classification Refinement: Hard False Positive Suppression for Object Detection</strong><br><img src="/2018/12/14/object_detection_paper_summarization/2.jpg" alt=""></p>
<h2 id="Anchor"><a href="#Anchor" class="headerlink" title="Anchor"></a>Anchor</h2><p>Anchors are regression references and classification candidates to predict proposals (for two-stage detectors) or final bounding boxes (for single-stage detectors). Modern object detection pipelines usually begin with a large set of densely distributed anchors. </p>
<p>Two general rules for a reasonable anchor design: (1)Alignment: anchor centers need to be well aligned with feature map pixels. (2)Consistency: the receptive field and semantic scope are consistent in different regions of a feature map, so the scale and shape of anchors across different locations should be consistent.</p>
<p>The uniform anchoring scheme can lead to two difficulties: (1) A neat set of anchors of fixed aspect ratios has to be predefined for different problems. A wrong design may hamper the speed and accuracy of the detector. (2) To maintain a sufficiently high recall for proposals, a large number of anchors are needed, while most of them correspond to false candidates that are irrelevant to the object of interests.</p>
<h3 id="Modify-anchor-generation-scheme"><a href="#Modify-anchor-generation-scheme" class="headerlink" title="Modify anchor generation scheme"></a>Modify anchor generation scheme</h3><p><strong>[Guided Anchoring - CVPR2019] Region Proposal by Guided Anchoring</strong><br>[paper] <a href="https://arxiv.org/abs/1901.03278" target="_blank" rel="noopener">https://arxiv.org/abs/1901.03278</a><br>[official code] <a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener">https://github.com/open-mmlab/mmdetection</a><br>[summarization]<br><img src="/2018/12/14/object_detection_paper_summarization/19.png" alt=""><br>(1)<em>Anchor Location Prediction</em>:<br>-a 1x1 convolution and an element-wise sigmoid function.<br>-yields a probability map that indicates the possible locations of the objects.<br>-selecting those locations whose corresponding probability values are above a predefined threshold.<br>-use masked convolution when inference<br>-define center/ignore/outside region, use focal loss when training</p>
<p>(2)<em>Anchor Shape Prediction</em>:<br>-predict the best shape (w; h) for each location.<br>-a 1x1 convolutional layer that yields a two-channel map that contains the values of dw and dh, an element-wise transform layer that implements Eq.(2).<br>  <img src="/2018/12/14/object_detection_paper_summarization/20.png" alt=""><br>-when training, sample some common values of w and h, calculate the IoU of these sampled anchors with gt, use the maximum. use bounded iou loss.</p>
<p>(3)<em>Anchor Guided Feature Adaptation</em><br>-Ideally, the feature for a large anchor should encode the content over a large region, while those for small anchors should have smaller scopes accordingly.<br>-first predict an offset field from the output of anchor shape prediction branch, and then apply 3x3 deformable convolution to the original feature map with the offsets.</p>
<p>(4)<em>The Use of High quality Proposals</em><br>-set a higher positive/negative threshold and use fewer samples when training detectors with GA-RPN compared to RPN.</p>
<h2 id="The-way-to-extract-fixed-length-feature-vector"><a href="#The-way-to-extract-fixed-length-feature-vector" class="headerlink" title="The way to extract fixed-length feature vector"></a>The way to extract fixed-length feature vector</h2><p><strong>RoI Pooling</strong> [Fast R-CNN]<br><strong>RoI Align</strong> [Mask R-CNN]<br><strong>Precise RoI Pooling</strong> [IoU-Net]</p>
<h1 id="Improvement-for-One-Stage-Framework"><a href="#Improvement-for-One-Stage-Framework" class="headerlink" title="Improvement for  One Stage Framework"></a>Improvement for  One Stage Framework</h1><h2 id="Foreground-background-class-imbalance-problem"><a href="#Foreground-background-class-imbalance-problem" class="headerlink" title="Foreground-background class imbalance problem"></a>Foreground-background class imbalance problem</h2><p>Class imbalance is addressed in R-CNN-like detectors by a two-stage cascade and sampling heuristics. The proposal stage (e.g., Selective Search, EdgeBoxes, DeepMask, RPN) rapidly narrows down the number of candidate object locations to a small number (e.g., 1-2k), filtering out most background samples. In the second classification stage, sampling heuristics, such as a fixed foreground-to-background ratio (1:3), or online hard example mining (OHEM), are performed to maintain a manageable balance between foreground and background.</p>
<p>In contrast, a one-stage detector must process a much larger set of candidate object locations regularly sampled across an image. In practice this often amounts to enumerating ~100k locations that densely cover spatial positions, scales, and aspect ratios. While similar sampling heuristics may also be applied, they are inefficient as the training procedure is still dominated by easily classified background examples.</p>
<h3 id="New-classification-loss-function"><a href="#New-classification-loss-function" class="headerlink" title="New classification loss function"></a>New classification loss function</h3><p><strong>[Focal Loss - ICCV2017] Focal Loss for Dense Object Detection</strong><br>[paper]<br>[summarization]<br>-Identify class imbalance during training as the main obstacle impeding one-stage detector from achieving state-of-the-art accuracy.</p>
<p>-<em>Focal Loss</em><br>Dynamically scaled cross entropy loss: down-weight the contribution of easy examples during training and rapidly focus the model on hard examples.<br><img src="/2018/12/14/object_detection_paper_summarization/27.png" alt=""></p>
<p>Consider the cross entropy (CE) loss for binary classification:<br><img src="/2018/12/14/object_detection_paper_summarization/29.png" alt=""><br>Rewrite it by pt:<br><img src="/2018/12/14/object_detection_paper_summarization/30.png" alt=""><br>Define the focal loss as<br><img src="/2018/12/14/object_detection_paper_summarization/28.png" alt=""></p>
<p>-<em>RetinaNet</em><br><img src="/2018/12/14/object_detection_paper_summarization/26.png" alt=""></p>
<h2 id="To-alleviate-the-problems-arising-from-scale-variation-and-small-object-instances-1"><a href="#To-alleviate-the-problems-arising-from-scale-variation-and-small-object-instances-1" class="headerlink" title="To alleviate the problems arising from scale variation and small object instances"></a>To alleviate the problems arising from scale variation and small object instances</h2><h3 id="Construct-feature-pyramid-1"><a href="#Construct-feature-pyramid-1" class="headerlink" title="Construct feature pyramid"></a>Construct feature pyramid</h3><p><strong>[PFPNet - ECCV2018] Parallel Feature Pyramid Network for Object Detection</strong><br>[paper]<br>[summarization]<br>-Employ the SPP module to generate pyramid-shaped feature maps via widening the network width instead of increasing its depth.</p>
<p>-SSD / RefineDet  VGG16<br><img src="/2018/12/14/object_detection_paper_summarization/9.png" alt=""><br><img src="/2018/12/14/object_detection_paper_summarization/10.png" alt=""></p>
<p><strong>[M2Det - AAAI2019] M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network</strong><br>[paper] <a href="https://arxiv.org/abs/1811.04533" target="_blank" rel="noopener">https://arxiv.org/abs/1811.04533</a><br>[official code] <a href="https://github.com/qijiezhao/M2Det" target="_blank" rel="noopener">https://github.com/qijiezhao/M2Det</a><br>[summarization]<br>-For previous feature pyramid method, each feature map (used for detecting objects in a specific range of size) in the pyramid mainly or only consists of single-level features will result in suboptimal detection performance.</p>
<p>-Multi-Level Feature Pyramid Network (MLFPN).</p>
<p>-Based on SSD<br><img src="/2018/12/14/object_detection_paper_summarization/6.png" alt=""><br><img src="/2018/12/14/object_detection_paper_summarization/7.png" alt=""><br><img src="/2018/12/14/object_detection_paper_summarization/8.png" alt=""></p>
<h2 id="Anchor-default-box"><a href="#Anchor-default-box" class="headerlink" title="Anchor(default box)"></a>Anchor(default box)</h2><p>In short, anchor method suggests dividing the box space (including position, size, class, etc.) into discrete bins (not necessarily disjoint) and generating each object box via the anchor function defined in the corresponding bin.</p>
<p>Currently most of the detectors model anchors via enumeration, i.e. predefining a number of anchor boxes with all kinds of positions, sizes and class labels, which leads to the following issues.First, anchor boxes need careful design (chosen by handcraft or statistical methods like clustering). Second, predefined anchor functions may cause too many parameters.</p>
<p><strong>[MetaAnchor - NIPS2018] MetaAnchor: Learning to Detect Objects with Customized Anchor</strong><br>[paper] <a href="https://arxiv.org/abs/1807.00980" target="_blank" rel="noopener">https://arxiv.org/abs/1807.00980</a><br>[summarization]</p>
<h3 id="Anchor-free-method"><a href="#Anchor-free-method" class="headerlink" title="Anchor free method"></a>Anchor free method</h3><h1 id="Other-improvement"><a href="#Other-improvement" class="headerlink" title="Other improvement"></a>Other improvement</h1><h1 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h1><h1 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h1><p><strong>[mmdetction]</strong> <a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener">https://github.com/open-mmlab/mmdetection</a></p>
<p><strong>[OneStageDet]</strong> <a href="https://github.com/TencentYoutuResearch/ObjectDetection-OneStageDet" target="_blank" rel="noopener">https://github.com/TencentYoutuResearch/ObjectDetection-OneStageDet</a></p>
<p><strong>[Detectron]</strong> <a href="https://github.com/facebookresearch/Detectron" target="_blank" rel="noopener">https://github.com/facebookresearch/Detectron</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/16/something_about_python/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/16/something_about_python/" itemprop="url">Something about Python</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-16T15:54:44+08:00">
                2018-11-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<p>[TOC]</p>
<hr>
<h3 id="lstrip-和rstrip"><a href="#lstrip-和rstrip" class="headerlink" title="lstrip()和rstrip()"></a>lstrip()和rstrip()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">str.lstrip([chars]) <span class="comment"># 删除字符串左边的空格或指定字符</span></span><br><span class="line">str.rstrip([chars]) <span class="comment"># 删除字符串末尾的空格或指定字符</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="字典中找最值"><a href="#字典中找最值" class="headerlink" title="字典中找最值"></a>字典中找最值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dogdistance = &#123;<span class="string">'dog-dog'</span>: <span class="number">33</span>, <span class="string">'dog-cat'</span>: <span class="number">36</span>, <span class="string">'dog-car'</span>: <span class="number">41</span>, <span class="string">'dog-bird'</span>: <span class="number">42</span>&#125;</span><br><span class="line">min(dogdistance, key=dogdistance.get) <span class="comment"># 返回最小值的键值：’dog-dog‘</span></span><br><span class="line">max(dogdistance, key=dogdistance.get) <span class="comment"># 返回最大值的键值：’dog-bird‘</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="列表中找最值"><a href="#列表中找最值" class="headerlink" title="列表中找最值"></a>列表中找最值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c = [<span class="number">-10</span>,<span class="number">-5</span>,<span class="number">0</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">-20</span>,<span class="number">25</span>]</span><br><span class="line"><span class="keyword">print</span> c.index(min(c))  <span class="comment"># 返回最小值的索引</span></span><br><span class="line"><span class="keyword">print</span> c.index(max(c)) <span class="comment"># 返回最大值的索引</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="字典按照value排序"><a href="#字典按照value排序" class="headerlink" title="字典按照value排序"></a>字典按照value排序</h3><p>返回list：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sorted(d.items(),key = <span class="keyword">lambda</span> x:x[<span class="number">1</span>],reverse = <span class="keyword">True</span>)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> operator</span><br><span class="line">sorted(d.items(),key = operator.itemgetter(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>返回只有键的tuple<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sorted(d,key=d.__getitem__)</span><br></pre></td></tr></table></figure></p>
<hr>
<h3 id="numpy-array-找最值"><a href="#numpy-array-找最值" class="headerlink" title="numpy array 找最值"></a>numpy array 找最值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">9</span>).reshape((<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">a</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">[<span class="number">9</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"> </span><br><span class="line">print(np.max(a)) <span class="comment">#全局最大</span></span><br><span class="line"><span class="number">8</span></span><br><span class="line">print(np.max(a,axis=<span class="number">0</span>)) <span class="comment">#每列最大</span></span><br><span class="line">[<span class="number">6</span> <span class="number">7</span> <span class="number">8</span>]</span><br><span class="line">print(np.max(a,axis=<span class="number">1</span>)) <span class="comment">#每行最大</span></span><br><span class="line">[<span class="number">2</span> <span class="number">5</span> <span class="number">8</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(np.where(a==np.max(a)))</span><br><span class="line">(array([<span class="number">2</span>], dtype=int64), array([<span class="number">2</span>], dtype=int64))</span><br><span class="line">print(np.where(a==np.max(a,axis=<span class="number">0</span>)))</span><br><span class="line">(array([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], dtype=int64), array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], dtype=int64))</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="List做除法"><a href="#List做除法" class="headerlink" title="List做除法"></a>List做除法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list(map(<span class="keyword">lambda</span> x: x//<span class="number">4</span>, list_a))</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/16/google_deeplab代码分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/16/google_deeplab代码分析/" itemprop="url">google_deeplab代码分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-16T10:18:03+08:00">
                2018-11-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>vis.py :</strong> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predictions = model.predict_labels(</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>-&gt;model.py</strong>  </p>
<p>def predict_labels()</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outputs_to_scales_to_logits = multi_scale_logits(</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>def multi_scale_logits()</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputs_to_logits = _get_logits()</span><br></pre></td></tr></table></figure>
<p>def _get_logits()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">features, end_point = extract_features()</span><br></pre></td></tr></table></figure>
<p>def extract_features()</p>
<p><strong>-&gt;core/feature_extractor.py</strong></p>
<p>def  extract_features()</p>
<p><code>model_variant</code>  [‘resnet’, ‘xception’, ‘mobilenet’, ‘nas’]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arg_scope = arg_scopes_map[model_variant]()</span><br><span class="line">features, end_point = get_network(model_variant,..., arg_scope)</span><br></pre></td></tr></table></figure>
<p>model_variant=’xception-XX’</p>
<p>-&gt; arg_scopes_map[model_variant]=xception_arg_scope</p>
<p><strong>-&gt;core/xception.py</strong></p>
<p>def xception_arg_scope()  不知道干啥的</p>
<p>def get_network()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">func = network_map[network_name]</span><br></pre></td></tr></table></figure>
<p><strong>-&gt;core/xception.py</strong></p>
<p>def xception_71()</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/16/yolov3-pytorch代码分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/16/yolov3-pytorch代码分析/" itemprop="url">yolov3-pytorch代码分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-16T10:18:03+08:00">
                2018-11-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>GitHub：<a href="https://github.com/ayooshkathuria/pytorch-yolo-v3" target="_blank" rel="noopener">https://github.com/ayooshkathuria/pytorch-yolo-v3</a></p>
<p>Tutorial： <a href="https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/" target="_blank" rel="noopener">Implement YOLO v3 from scratch</a> </p>
<hr>
<h1 id="1-Creating-the-layers-of-the-network-architecture"><a href="#1-Creating-the-layers-of-the-network-architecture" class="headerlink" title="1. Creating the layers of the network architecture"></a>1. Creating the layers of the network architecture</h1><h2 id="Configuration-File"><a href="#Configuration-File" class="headerlink" title="Configuration File"></a>Configuration File</h2><p>The configuration  file <a href="https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg" target="_blank" rel="noopener">here</a> describes the layout of the network, block by block. You can also see the full architecture Darknet-53 in the folloing diagram.</p>
<p><img src="/2018/11/16/yolov3-pytorch代码分析/1.png" alt=""></p>
<p>There are 5 types of layers that are used in YOLO:</p>
<p><strong><em>Convolutional</em></strong></p>
<p><strong><em>Shortcut（Residual）</em></strong>: 参数<code>from:-3</code>表示shortcut的output等于倒数第三层的output与前一层output相加</p>
<p><strong><em>Upsample</em></strong>: YOLO3采用了类似FPN的结构，在三个尺度上进行预测，故要做两次unsample</p>
<p><strong><em>Route</em></strong>：<br>When layers attribute has only one value, it outputs the feature maps of the layer indexed by the value. In our example, it is -4, so the layer will output feature map from the 4th layer backwards from the Route layer.</p>
<p>When layers has two values, it returns the concatenated feature maps of the layers indexed by it’s values. In our example it is -1, 61, and the layer will output feature maps from the previous layer (-1) and the 61st layer, concatenated along the depth dimension.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[route]</span><br><span class="line">layers = -4</span><br><span class="line"></span><br><span class="line">[route]</span><br><span class="line">layers = -1, 61</span><br></pre></td></tr></table></figure></p>
<p><strong><em>YOLO</em></strong>：<br>The anchors describes 9 anchors, but only the anchors which are indexed by attributes of the mask tag are used. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[yolo]</span><br><span class="line">mask = 0,1,2</span><br><span class="line">anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326</span><br><span class="line">classes=80</span><br><span class="line">num=9</span><br><span class="line">jitter=.3</span><br><span class="line">ignore_thresh = .5</span><br><span class="line">truth_thresh = 1</span><br><span class="line">random=1</span><br></pre></td></tr></table></figure>
<h2 id="Parsing-the-configuration-file"><a href="#Parsing-the-configuration-file" class="headerlink" title="Parsing the configuration file"></a>Parsing the configuration file</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_cfg</span><span class="params">(cfgfile)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Takes a configuration file</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns a list of blocks. Each blocks describes a block in the neural</span></span><br><span class="line"><span class="string">    network to be built. Block is represented as a dictionary in the list</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    """</span></span><br></pre></td></tr></table></figure>
<h2 id="Creating-the-building-blocks"><a href="#Creating-the-building-blocks" class="headerlink" title="Creating the building blocks"></a>Creating the building blocks</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_modules</span><span class="params">(blocks)</span>:</span></span><br><span class="line">    net_info = blocks[<span class="number">0</span>]     <span class="comment">#Captures the information about the input and pre-processing    </span></span><br><span class="line">    module_list = nn.ModuleList()</span><br><span class="line">    prev_filters = <span class="number">3</span></span><br><span class="line">    output_filters = []</span><br></pre></td></tr></table></figure>
<p>Our function will return a <code>nn.ModuleList</code> .</p>
<p><code>prev_filters</code> is used to keep track of number of filters in the layer on which the convolutional layer is being applied. </p>
<p><code>output_filters</code> is used to store the number of output filters of each block, for route layer need.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for x in blocks:</span><br><span class="line">    module = nn.Sequential()</span><br></pre></td></tr></table></figure>
<p><code>nn.Sequential</code> class is used to sequentially execute a number of nn.Module objects. We use it’s <code>add_module</code> function to string together all layers.</p>
<p><strong>for conv layer and unsample layer</strong>:(PyTorch has provided pre-built layers)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Add the convolutional layer</span></span><br><span class="line">conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias = bias)</span><br><span class="line">module.add_module(<span class="string">"conv_&#123;0&#125;"</span>.format(index), conv)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Add the Batch Norm Layer</span></span><br><span class="line">bn = nn.BatchNorm2d(filters)</span><br><span class="line">module.add_module(<span class="string">"batch_norm_&#123;0&#125;"</span>.format(index), bn)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Check the activation. </span></span><br><span class="line"><span class="comment">#It is either Linear or a Leaky ReLU for YOLO</span></span><br><span class="line">activn = nn.LeakyReLU(<span class="number">0.1</span>, inplace = <span class="keyword">True</span>)</span><br><span class="line">module.add_module(<span class="string">"leaky_&#123;0&#125;"</span>.format(index), activn)</span><br><span class="line"></span><br><span class="line"><span class="comment">#If it's an upsampling layer</span></span><br><span class="line"><span class="comment">#We use Bilinear2dUpsampling</span></span><br><span class="line">upsample = nn.Upsample(scale_factor = <span class="number">2</span>, mode = <span class="string">"bilinear"</span>)</span><br><span class="line">module.add_module(<span class="string">"upsample_&#123;&#125;"</span>.format(index), upsample)</span><br></pre></td></tr></table></figure>
<p><strong>for Route Layer / Shortcut Layers</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">shortcut = EmptyLayer()</span><br><span class="line">module.add_module(<span class="string">"shortcut_&#123;&#125;"</span>.format(index), shortcut)</span><br><span class="line"></span><br><span class="line">route = EmptyLayer()</span><br><span class="line">module.add_module(<span class="string">"route_&#123;0&#125;"</span>.format(index), route)</span><br></pre></td></tr></table></figure>
<p>The empty layer is defined as:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EmptyLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(EmptyLayer, self).__init__()</span><br></pre></td></tr></table></figure></p>
<p>We use empty layer and  perform the concatenation directly in the<code>forward</code> function of the <code>nn.Module</code> object representing darknet.</p>
<p><strong>for yolo layers</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">detection = DetectionLayer(anchors)</span><br><span class="line">module.add_module(<span class="string">"Detection_&#123;&#125;"</span>.format(index), detection)</span><br></pre></td></tr></table></figure>
<p>We define a new layer<code>DetectionLayer</code> that holds the anchors used to detect bounding boxes.</p>
<p>The detection layer is defined as: (the <code>forward</code> function will be proposed later)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DetectionLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, anchors)</span>:</span></span><br><span class="line">        super(DetectionLayer, self).__init__()</span><br><span class="line">        self.anchors = anchors</span><br></pre></td></tr></table></figure></p>
<p>At the end of the loop for each block， we do some bookkeeping.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">module_list.append(module)</span><br><span class="line">prev_filters = filters</span><br><span class="line">output_filters.append(filters)</span><br><span class="line">index += <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>At the end of the function <code>create_modules</code>, we return a tuple containing the <code>net_info</code>, and <code>module_list</code>.</p>
<h1 id="2-Implementing-the-the-forward-pass-of-the-network"><a href="#2-Implementing-the-the-forward-pass-of-the-network" class="headerlink" title="2. Implementing the the forward pass of the network"></a>2. Implementing the the forward pass of the network</h1><h2 id="Defining-the-Network"><a href="#Defining-the-Network" class="headerlink" title="Defining the Network"></a>Defining the Network</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Darknet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, cfgfile)</span>:</span></span><br><span class="line">        super(Darknet, self).__init__()</span><br><span class="line">        self.blocks = parse_cfg(cfgfile)</span><br><span class="line">        self.net_info, self.module_list = create_modules(self.blocks)</span><br></pre></td></tr></table></figure>
<h2 id="Implementing-the-forward-pass-of-the-network"><a href="#Implementing-the-forward-pass-of-the-network" class="headerlink" title="Implementing the forward pass of the network"></a>Implementing the forward pass of the network</h2><p><code>forward</code> serves two purposes. First, to calculate the output, and second, to transform the output detection feature maps in a way that it can be processed easier</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, CUDA)</span>:</span></span><br><span class="line">    modules = self.blocks[<span class="number">1</span>:]  <span class="comment"># the first element is net layer which is no use</span></span><br><span class="line">    outputs = &#123;&#125;   <span class="comment"># We cache the outputs for the route layer</span></span><br><span class="line">    </span><br><span class="line">    write = <span class="number">0</span>     <span class="comment">#This is explained a bit later</span></span><br><span class="line">	<span class="keyword">for</span> i, module <span class="keyword">in</span> enumerate(modules):        </span><br><span class="line">    	module_type = (module[<span class="string">"type"</span>])</span><br></pre></td></tr></table></figure>
<p>Since route and shortcut layers need output maps from previous layers, we cache the output feature maps of every layer in a dict <code>outputs</code>. The keys are the the indices of the layers, and the values are the feature maps.</p>
<h2 id="Convolutional-and-Upsample-Layers"><a href="#Convolutional-and-Upsample-Layers" class="headerlink" title="Convolutional and Upsample Layers"></a>Convolutional and Upsample Layers</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> module_type == <span class="string">"convolutional"</span> <span class="keyword">or</span> module_type == <span class="string">"upsample"</span>:</span><br><span class="line">    x = self.module_list[i](x)</span><br></pre></td></tr></table></figure>
<h2 id="Route-Layer-Shortcut-Layer"><a href="#Route-Layer-Shortcut-Layer" class="headerlink" title="Route Layer / Shortcut Layer"></a>Route Layer / Shortcut Layer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> module_type == <span class="string">"route"</span>:</span><br><span class="line">    layers = module[<span class="string">"layers"</span>]</span><br><span class="line">    layers = [int(a) <span class="keyword">for</span> a <span class="keyword">in</span> layers]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (layers[<span class="number">0</span>]) &gt; <span class="number">0</span>:</span><br><span class="line">        layers[<span class="number">0</span>] = layers[<span class="number">0</span>] - i</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(layers) == <span class="number">1</span>:</span><br><span class="line">        x = outputs[i + (layers[<span class="number">0</span>])]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> (layers[<span class="number">1</span>]) &gt; <span class="number">0</span>:</span><br><span class="line">            layers[<span class="number">1</span>] = layers[<span class="number">1</span>] - i</span><br><span class="line"></span><br><span class="line">        map1 = outputs[i + layers[<span class="number">0</span>]]</span><br><span class="line">        map2 = outputs[i + layers[<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">        x = torch.cat((map1, map2), <span class="number">1</span>) <span class="comment"># concatenate the feature maps along the depth</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">elif</span>  module_type == <span class="string">"shortcut"</span>:</span><br><span class="line">    from_ = int(module[<span class="string">"from"</span>])</span><br><span class="line">    x = outputs[i<span class="number">-1</span>] + outputs[i+from_]</span><br></pre></td></tr></table></figure>
<p>In PyTorch, input and output of a convolutional layer has the format B x C x H x W. The depth corresponding the the channel dimension.</p>
<h2 id="YOLO-Detection-Layer"><a href="#YOLO-Detection-Layer" class="headerlink" title="YOLO (Detection Layer)"></a>YOLO (Detection Layer)</h2><p>The output of YOLO is a convolutional feature map that contains the bounding box attributes along the depth of the feature map. </p>
<p>There are two problems. First, the attributes bounding boxes predicted by a cell are stacked one by one along each other,  this form is very inconvenient for output processing. Second, it would be nice to have to do these operations on a single tensor, rather than three separate tensors.</p>
<p>To remedy these problems, we will introduce the function <code>predict_transform</code> first.</p>
<h2 id="Transforming-the-output"><a href="#Transforming-the-output" class="headerlink" title="Transforming the output"></a>Transforming the output</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_transform</span><span class="params">(prediction, inp_dim, anchors, num_classes, CUDA = True)</span>:</span></span><br></pre></td></tr></table></figure>
<p>This function takes an detection feature map and turns it into a 2-D tensor, where each row of the tensor corresponds to attributes of a bounding box, in the following order .<br><img src="/2018/11/16/yolov3-pytorch代码分析/32.png" alt=""></p>
<p>The code to do above transformation is:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">batch_size = prediction.size(<span class="number">0</span>)</span><br><span class="line">stride =  inp_dim // prediction.size(<span class="number">2</span>)</span><br><span class="line">grid_size = inp_dim // stride</span><br><span class="line">bbox_attrs = <span class="number">5</span> + num_classes</span><br><span class="line">num_anchors = len(anchors)</span><br><span class="line"></span><br><span class="line">prediction = prediction.view(batch_size, bbox_attrs*num_anchors, grid_size*grid_size)</span><br><span class="line">prediction = prediction.transpose(<span class="number">1</span>,<span class="number">2</span>).contiguous()</span><br><span class="line">prediction = prediction.view(batch_size, grid_size*grid_size*num_anchors, bbox_attrs)</span><br></pre></td></tr></table></figure></p>
<p>The dimensions of the anchors are in accordance to the <code>height</code> and <code>width</code> attributes of the <code>net</code> block. These attributes describe the dimensions of the input image, which is larger (by a factor of stride) than the detection map. Therefore, we must divide the anchors by the stride of the detection feature map.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">anchors = [(a[<span class="number">0</span>]/stride, a[<span class="number">1</span>]/stride) <span class="keyword">for</span> a <span class="keyword">in</span> anchors]</span><br></pre></td></tr></table></figure></p>
<p>Now, we need to transform our output according to the equations<br><img src="/2018/11/16/yolov3-pytorch代码分析/4.png" alt=""></p>
<p>First, sigmoid the x,y coordinates and the objectness score.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Sigmoid the  centre_X, centre_Y. and object confidencce</span></span><br><span class="line">prediction[:,:,<span class="number">0</span>] = torch.sigmoid(prediction[:,:,<span class="number">0</span>])</span><br><span class="line">prediction[:,:,<span class="number">1</span>] = torch.sigmoid(prediction[:,:,<span class="number">1</span>])</span><br><span class="line">prediction[:,:,<span class="number">4</span>] = torch.sigmoid(prediction[:,:,<span class="number">4</span>])</span><br></pre></td></tr></table></figure></p>
<p>Add the grid offsets to the center cordinates prediction.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Add the center offsets</span></span><br><span class="line">grid = np.arange(grid_size)</span><br><span class="line">a,b = np.meshgrid(grid, grid)</span><br><span class="line"></span><br><span class="line">x_offset = torch.FloatTensor(a).view(<span class="number">-1</span>,<span class="number">1</span>)</span><br><span class="line">y_offset = torch.FloatTensor(b).view(<span class="number">-1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> CUDA:</span><br><span class="line">    x_offset = x_offset.cuda()</span><br><span class="line">    y_offset = y_offset.cuda()</span><br><span class="line"></span><br><span class="line">x_y_offset = torch.cat((x_offset, y_offset), <span class="number">1</span>).repeat(<span class="number">1</span>,num_anchors).view(<span class="number">-1</span>,<span class="number">2</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">prediction[:,:,:<span class="number">2</span>] += x_y_offset</span><br></pre></td></tr></table></figure></p>
<p>Apply the anchors to the dimensions of the bounding box.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#log space transform height and the width</span></span><br><span class="line">anchors = torch.FloatTensor(anchors)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> CUDA:</span><br><span class="line">    anchors = anchors.cuda()</span><br><span class="line"></span><br><span class="line">anchors = anchors.repeat(grid_size*grid_size, <span class="number">1</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">prediction[:,:,<span class="number">2</span>:<span class="number">4</span>] = torch.exp(prediction[:,:,<span class="number">2</span>:<span class="number">4</span>])*anchors</span><br></pre></td></tr></table></figure></p>
<p>Apply sigmoid activation to the the class scores.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prediction[:,:,<span class="number">5</span>: <span class="number">5</span> + num_classes] = torch.sigmoid((prediction[:,:, <span class="number">5</span> : <span class="number">5</span> + num_classes]))</span><br></pre></td></tr></table></figure></p>
<p>The last thing we want to do here, is to resize the detections map to the size of the input image. The bounding box attributes here are sized according to the feature map (say, 13 x 13). If the input image was 416 x 416, we multiply the attributes by 32, or the <code>stride</code> variable.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">prediction[:,:,:<span class="number">4</span>] *= stride</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> prediction</span><br></pre></td></tr></table></figure></p>
<h2 id="Detection-Layer-Revisited"><a href="#Detection-Layer-Revisited" class="headerlink" title="Detection Layer Revisited"></a>Detection Layer Revisited</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> module_type == <span class="string">'yolo'</span>:        </span><br><span class="line">    anchors = self.module_list[i][<span class="number">0</span>].anchors</span><br><span class="line">    <span class="comment">#Get the input dimensions</span></span><br><span class="line">    inp_dim = int (self.net_info[<span class="string">"height"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Get the number of classes</span></span><br><span class="line">    num_classes = int (module[<span class="string">"classes"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Transform </span></span><br><span class="line">    x = x.data</span><br><span class="line">    x = predict_transform(x, inp_dim, anchors, num_classes, CUDA)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> write:              <span class="comment">#if no collector has been intialised. </span></span><br><span class="line">        detections = x</span><br><span class="line">        write = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:       </span><br><span class="line">        detections = torch.cat((detections, x), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">outputs[i] = x</span><br><span class="line"></span><br><span class="line">rturn detections</span><br></pre></td></tr></table></figure>
<h1 id="3-Confidence-Thresholding-and-Non-maximum-Suppression"><a href="#3-Confidence-Thresholding-and-Non-maximum-Suppression" class="headerlink" title="3. Confidence Thresholding and Non-maximum Suppression"></a>3. Confidence Thresholding and Non-maximum Suppression</h1><p>To be precise, our output is a tensor of shape <code>B x 10647 x 85</code>. B is the number of images in a batch, 10647 is the number of bounding boxes predicted per image, and 85 is the number of bounding box attributes.</p>
<p>However,  we must subject our output to objectness score thresholding and Non-maximal suppression, to obtain what we will call in the rest of this post as the<em>true</em> detections. To do that, we will create a function called <code>write_results</code>.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_results</span><span class="params">(prediction, confidence, num_classes, nms_conf = <span class="number">0.4</span>)</span>:</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Object-Confidence-Thresholding"><a href="#Object-Confidence-Thresholding" class="headerlink" title="Object Confidence Thresholding"></a>Object Confidence Thresholding</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conf_mask = (prediction[:,:,<span class="number">4</span>] &gt; confidence).float().unsqueeze(<span class="number">2</span>)</span><br><span class="line">prediction = prediction*conf_mask</span><br></pre></td></tr></table></figure>
<h2 id="Performing-Non-maximum-Suppression"><a href="#Performing-Non-maximum-Suppression" class="headerlink" title="Performing Non-maximum Suppression"></a>Performing Non-maximum Suppression</h2><p>Transform the (center x, center y, height, width) attributes of our boxes, to (top-left corner x, top-left corner y, right-bottom corner x, right-bottom corner y).<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">box_corner = prediction.new(prediction.shape)</span><br><span class="line">box_corner[:,:,<span class="number">0</span>] = (prediction[:,:,<span class="number">0</span>] - prediction[:,:,<span class="number">2</span>]/<span class="number">2</span>)</span><br><span class="line">box_corner[:,:,<span class="number">1</span>] = (prediction[:,:,<span class="number">1</span>] - prediction[:,:,<span class="number">3</span>]/<span class="number">2</span>)</span><br><span class="line">box_corner[:,:,<span class="number">2</span>] = (prediction[:,:,<span class="number">0</span>] + prediction[:,:,<span class="number">2</span>]/<span class="number">2</span>) </span><br><span class="line">box_corner[:,:,<span class="number">3</span>] = (prediction[:,:,<span class="number">1</span>] + prediction[:,:,<span class="number">3</span>]/<span class="number">2</span>)</span><br><span class="line">prediction[:,:,:<span class="number">4</span>] = box_corner[:,:,:<span class="number">4</span>]</span><br></pre></td></tr></table></figure></p>
<p>Confidence thresholding and NMS has to be done for one image at once. This means, we must loop over the first dimension of <code>prediction</code>.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">batch_size = prediction.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">write = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ind <span class="keyword">in</span> range(batch_size):</span><br><span class="line">    image_pred = prediction[ind]          <span class="comment">#image Tensor</span></span><br><span class="line">       <span class="comment">#confidence threshholding </span></span><br><span class="line">       <span class="comment">#NMS</span></span><br></pre></td></tr></table></figure></p>
<p>Notice each bounding box row has 85 attributes, out of which 80 are the class scores. At this point, we’re only concerned with the class score having the maximum value. So, we remove the 80 class scores from each row, and instead add the index of the class having the maximum values, as well the class score of that class.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">max_conf, max_conf_score = torch.max(image_pred[:,<span class="number">5</span>:<span class="number">5</span>+ num_classes], <span class="number">1</span>)</span><br><span class="line">max_conf = max_conf.float().unsqueeze(<span class="number">1</span>)</span><br><span class="line">max_conf_score = max_conf_score.float().unsqueeze(<span class="number">1</span>)</span><br><span class="line">seq = (image_pred[:,:<span class="number">5</span>], max_conf, max_conf_score)</span><br><span class="line">image_pred = torch.cat(seq, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>Get rid of  the bounding box rows having a object confidence less than the threshold.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">non_zero_ind =  (torch.nonzero(image_pred[:,<span class="number">4</span>]))</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    image_pred_ = image_pred[non_zero_ind.squeeze(),:].view(<span class="number">-1</span>,<span class="number">7</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#For PyTorch 0.4 compatibility</span></span><br><span class="line"><span class="comment">#Since the above code with not raise exception for no detection </span></span><br><span class="line"><span class="comment">#as scalars are supported in PyTorch 0.4</span></span><br><span class="line"><span class="keyword">if</span> image_pred_.shape[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">continue</span></span><br></pre></td></tr></table></figure></p>
<p>The try-except block is there to handle situations where we get no detections. In that case, we use <code>continue</code> to skip the rest of the loop body for this image.</p>
<p>Now, let’s get the classes detected in a an image.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Get the various classes detected in the image</span></span><br><span class="line">img_classes = unique(image_pred_[:,<span class="number">-1</span>]) <span class="comment"># -1 index holds the class index</span></span><br></pre></td></tr></table></figure></p>
<p>Since there can be multiple true detections of the same class, we use a function called <code>unique</code> to get classes present in any given image.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unique</span><span class="params">(tensor)</span>:</span></span><br><span class="line">    tensor_np = tensor.cpu().numpy()</span><br><span class="line">    unique_np = np.unique(tensor_np)</span><br><span class="line">    unique_tensor = torch.from_numpy(unique_np)</span><br><span class="line">    </span><br><span class="line">    tensor_res = tensor.new(unique_tensor.shape)</span><br><span class="line">    tensor_res.copy_(unique_tensor)</span><br><span class="line">    <span class="keyword">return</span> tensor_res</span><br></pre></td></tr></table></figure></p>
<p>Then, we perform NMS classwise.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> cls <span class="keyword">in</span> img_classes:</span><br><span class="line">    <span class="comment">#perform NMS</span></span><br></pre></td></tr></table></figure></p>
<p>Once we are inside the loop, the first thing we do is extract the detections of a particular class (denoted by variable <code>cls</code>).<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#get the detections with one particular class</span></span><br><span class="line">cls_mask = image_pred_*(image_pred_[:,<span class="number">-1</span>] == cls).float().unsqueeze(<span class="number">1</span>)</span><br><span class="line">class_mask_ind = torch.nonzero(cls_mask[:,<span class="number">-2</span>]).squeeze()</span><br><span class="line">image_pred_class = image_pred_[class_mask_ind].view(<span class="number">-1</span>,<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#sort the detections such that the entry with the maximum objectness confidence is at the top</span></span><br><span class="line">conf_sort_index = torch.sort(image_pred_class[:,<span class="number">4</span>], descending = <span class="keyword">True</span> )[<span class="number">1</span>]</span><br><span class="line">image_pred_class = image_pred_class[conf_sort_index]</span><br><span class="line">idx = image_pred_class.size(<span class="number">0</span>)   <span class="comment">#Number of detections</span></span><br></pre></td></tr></table></figure></p>
<p>Now, we perform NMS.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(idx):</span><br><span class="line">    <span class="comment">#Get the IOUs of all boxes that come after the one we are looking at </span></span><br><span class="line">    <span class="comment">#in the loop</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ious = bbox_iou(image_pred_class[i].unsqueeze(<span class="number">0</span>), image_pred_class[i+<span class="number">1</span>:])</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> IndexError:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#Zero out all the detections that have IoU &gt; treshhold</span></span><br><span class="line">    iou_mask = (ious &lt; nms_conf).float().unsqueeze(<span class="number">1</span>)</span><br><span class="line">    image_pred_class[i+<span class="number">1</span>:] *= iou_mask       </span><br><span class="line"></span><br><span class="line">    <span class="comment">#Remove the non-zero entries</span></span><br><span class="line">    non_zero_ind = torch.nonzero(image_pred_class[:,<span class="number">4</span>]).squeeze()</span><br><span class="line">    image_pred_class = image_pred_class[non_zero_ind].view(<span class="number">-1</span>,<span class="number">7</span>)</span><br></pre></td></tr></table></figure></p>
<p>Here, we use a function <code>bbox_iou</code>. The first input is the bounding box row that is indexed by the the variable <code>i</code> in the loop.<br>Second input is a tensor of multiple rows of bounding boxes. The output of the function <code>bbox_iou</code> is a tensor containing IoUs of the bounding box represented by the first input with each of the bounding boxes present in the second input.<br>If we have two bounding boxes of the same class having an IoU larger than a threshold, then the one with lower class confidence is eliminated. </p>
<p>Also notice, we have put the line of code to compute the ious in a <code>try-catch</code> block. This is because the loop is designed to run <code>idx</code> iterations. However, as we proceed with the loop, a number of bounding boxes may be removed from <code>image_pred_class</code>. This means, we cannot have idx iterations in most instances. Hence, we might try to index a value that is out of bounds (<code>IndexError</code>), or the slice <code>image_pred_class[i+1:]</code> may return an empty tensor, assigning which triggers a <code>ValueError</code>. At that point, we can ascertain that NMS can remove no further bounding boxes, and we break out of the loop.</p>
<p><strong>Calculating the IoU</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bbox_iou</span><span class="params">(box1, box2)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Returns the IoU of two bounding boxes </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">#Get the coordinates of bounding boxes</span></span><br><span class="line">    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:,<span class="number">0</span>], box1[:,<span class="number">1</span>], box1[:,<span class="number">2</span>], box1[:,<span class="number">3</span>]</span><br><span class="line">    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:,<span class="number">0</span>], box2[:,<span class="number">1</span>], box2[:,<span class="number">2</span>], box2[:,<span class="number">3</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#get the corrdinates of the intersection rectangle</span></span><br><span class="line">    inter_rect_x1 =  torch.max(b1_x1, b2_x1)</span><br><span class="line">    inter_rect_y1 =  torch.max(b1_y1, b2_y1)</span><br><span class="line">    inter_rect_x2 =  torch.min(b1_x2, b2_x2)</span><br><span class="line">    inter_rect_y2 =  torch.min(b1_y2, b2_y2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Intersection area</span></span><br><span class="line">    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + <span class="number">1</span>, min=<span class="number">0</span>) * torch.clamp(inter_rect_y2 - inter_rect_y1 + <span class="number">1</span>, min=<span class="number">0</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="comment">#Union Area</span></span><br><span class="line">    b1_area = (b1_x2 - b1_x1 + <span class="number">1</span>)*(b1_y2 - b1_y1 + <span class="number">1</span>)</span><br><span class="line">    b2_area = (b2_x2 - b2_x1 + <span class="number">1</span>)*(b2_y2 - b2_y1 + <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    iou = inter_area / (b1_area + b2_area - inter_area)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure></p>
<h2 id="Writing-the-predictions"><a href="#Writing-the-predictions" class="headerlink" title="Writing the predictions"></a>Writing the predictions</h2><p>The function <code>write_results</code> outputs a tensor of shape D x 8. Here D is the true detections in all of images, each represented by a row. Each detections has 8 attributes, namely, <strong>index of the image in the batch to which the detection belongs to, 4 corner coordinates, objectness score, the score of class with maximum confidence, and the index of that class.</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">batch_ind = image_pred_class.new(image_pred_class.size(<span class="number">0</span>), <span class="number">1</span>).fill_(ind)      </span><br><span class="line"><span class="comment">#Repeat the batch_id for as many detections of the class cls in the image</span></span><br><span class="line">seq = batch_ind, image_pred_class</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> write:</span><br><span class="line">    output = torch.cat(seq,<span class="number">1</span>)</span><br><span class="line">    write = <span class="keyword">True</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    out = torch.cat(seq,<span class="number">1</span>)</span><br><span class="line">    output = torch.cat((output,out))</span><br></pre></td></tr></table></figure></p>
<h1 id="4-Designing-the-input-and-the-output-pipelines"><a href="#4-Designing-the-input-and-the-output-pipelines" class="headerlink" title="4. Designing the input and the output pipelines"></a>4. Designing the input and the output pipelines</h1><h2 id="Loading-the-Network"><a href="#Loading-the-Network" class="headerlink" title="Loading the Network"></a>Loading the Network</h2><p>Load the class file.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_classes = <span class="number">80</span>    <span class="comment">#For COCO</span></span><br><span class="line">classes = load_classes(<span class="string">"data/coco.names"</span>)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_classes</span><span class="params">(namesfile)</span>:</span></span><br><span class="line">    fp = open(namesfile, <span class="string">"r"</span>)</span><br><span class="line">    names = fp.read().split(<span class="string">"\n"</span>)[:<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> names</span><br></pre></td></tr></table></figure>
<p>Initialize the network and load weights.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Set up the neural network</span></span><br><span class="line">print(<span class="string">"Loading network....."</span>)</span><br><span class="line">model = Darknet(args.cfgfile)</span><br><span class="line">model.load_weights(args.weightsfile)</span><br><span class="line">print(<span class="string">"Network successfully loaded"</span>)</span><br><span class="line"></span><br><span class="line">model.net_info[<span class="string">"height"</span>] = args.reso</span><br><span class="line">inp_dim = int(model.net_info[<span class="string">"height"</span>])</span><br><span class="line"><span class="keyword">assert</span> inp_dim % <span class="number">32</span> == <span class="number">0</span> </span><br><span class="line"><span class="keyword">assert</span> inp_dim &gt; <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#If there's a GPU availible, put the model on GPU</span></span><br><span class="line"><span class="keyword">if</span> CUDA:</span><br><span class="line">    model.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment">#Set the model in evaluation mode</span></span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure></p>
<h2 id="Read-the-Input-images"><a href="#Read-the-Input-images" class="headerlink" title="Read the Input images"></a>Read the Input images</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">read_dir = time.time()</span><br><span class="line"><span class="comment">#Detection phase</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    imlist = [osp.join(osp.realpath(<span class="string">'.'</span>), images, img) <span class="keyword">for</span> img <span class="keyword">in</span> os.listdir(images)]</span><br><span class="line"><span class="keyword">except</span> NotADirectoryError:</span><br><span class="line">    imlist = []</span><br><span class="line">    imlist.append(osp.join(osp.realpath(<span class="string">'.'</span>), images))</span><br><span class="line"><span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"No file or directory with the name &#123;&#125;"</span>.format(images))</span><br><span class="line">    exit()</span><br></pre></td></tr></table></figure>
<p>use OpenCV to load the images.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">load_batch = time.time()</span><br><span class="line">loaded_ims = [cv2.imread(x) <span class="keyword">for</span> x <span class="keyword">in</span> imlist]</span><br></pre></td></tr></table></figure></p>
<p>Write the function <code>letterbox_image</code> to resizes our image, keeping the aspect ratio consistent, and padding the left out areas with the color (128,128,128).<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">letterbox_image</span><span class="params">(img, inp_dim)</span>:</span></span><br><span class="line">    <span class="string">'''resize image with unchanged aspect ratio using padding'''</span></span><br><span class="line">    img_w, img_h = img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>]</span><br><span class="line">    w, h = inp_dim</span><br><span class="line">    new_w = int(img_w * min(w/img_w, h/img_h))</span><br><span class="line">    new_h = int(img_h * min(w/img_w, h/img_h))</span><br><span class="line">    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)</span><br><span class="line">    </span><br><span class="line">    canvas = np.full((inp_dim[<span class="number">1</span>], inp_dim[<span class="number">0</span>], <span class="number">3</span>), <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">    canvas[(h-new_h)//<span class="number">2</span>:(h-new_h)//<span class="number">2</span> + new_h,(w-new_w)//<span class="number">2</span>:(w-new_w)//<span class="number">2</span> + new_w,  :] = resized_image</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> canvas</span><br></pre></td></tr></table></figure></p>
<p>Write the function <code>prep_image</code> to takes a OpenCV images and converts it to PyTorch’s input format.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prep_image</span><span class="params">(img, inp_dim)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Prepare image for inputting to the neural network. </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns a Variable </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    img = cv2.resize(img, (inp_dim, inp_dim))</span><br><span class="line">    img = img[:,:,::<span class="number">-1</span>].transpose((<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>)).copy()</span><br><span class="line">    img = torch.from_numpy(img).float().div(<span class="number">255.0</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/16/leetcode412/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/16/leetcode412/" itemprop="url">【leetcode】412：Fizz Buzz</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-16T09:47:03+08:00">
                2018-11-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Fizz-Buzz"><a href="#Fizz-Buzz" class="headerlink" title="Fizz Buzz"></a>Fizz Buzz</h1><p><strong>难度：Easy</strong></p>
<h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><p>写一个程序，输出从 1 到 n 数字的字符串表示。</p>
<ol>
<li><p>如果 n 是3的倍数，输出“Fizz”；</p>
</li>
<li><p>如果 n 是5的倍数，输出“Buzz”；</p>
</li>
<li><p>如果 n 同时是3和5的倍数，输出 “FizzBuzz”。</p>
</li>
</ol>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">n = 15,</span><br><span class="line"></span><br><span class="line">返回:</span><br><span class="line">[</span><br><span class="line">    &quot;1&quot;,</span><br><span class="line">    &quot;2&quot;,</span><br><span class="line">    &quot;Fizz&quot;,</span><br><span class="line">    &quot;4&quot;,</span><br><span class="line">    &quot;Buzz&quot;,</span><br><span class="line">    &quot;Fizz&quot;,</span><br><span class="line">    &quot;7&quot;,</span><br><span class="line">    &quot;8&quot;,</span><br><span class="line">    &quot;Fizz&quot;,</span><br><span class="line">    &quot;Buzz&quot;,</span><br><span class="line">    &quot;11&quot;,</span><br><span class="line">    &quot;Fizz&quot;,</span><br><span class="line">    &quot;13&quot;,</span><br><span class="line">    &quot;14&quot;,</span><br><span class="line">    &quot;FizzBuzz&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h2 id="解"><a href="#解" class="headerlink" title="解"></a>解</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; fizzBuzz(<span class="keyword">int</span> n) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; res;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i % <span class="number">15</span> == <span class="number">0</span>) res.push_back(<span class="string">"FizzBuzz"</span>);</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (i % <span class="number">3</span> == <span class="number">0</span>) res.push_back(<span class="string">"Fizz"</span>);</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (i % <span class="number">5</span> == <span class="number">0</span>) res.push_back(<span class="string">"Buzz"</span>);</span><br><span class="line">            <span class="keyword">else</span> res.push_back(to_string(i));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="知识点："><a href="#知识点：" class="headerlink" title="知识点："></a>知识点：</h3><ol>
<li>向量（Vector）是一个封装了动态大小数组的顺序容器（Sequence Container）。跟任意其它类型容器一样，它能够存放各种类型的对象。可以简单的认为，向量是一个能够存放任意类型的动态数组。 </li>
</ol>
<p>标准库vector类型使用须要的头文件：<code>#include &lt;vector&gt;</code>。</p>
<p>Vector的定义和初始化：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt; typeName &gt; v1;       <span class="comment">//默认v1为空，故以下的赋值是错误的v1[0]=5;</span></span><br><span class="line"><span class="built_in">vector</span>&lt;typeName&gt;v2(v1); 或v2=v1;或<span class="built_in">vector</span>&lt;typeName&gt; v2(v1.begin(), v1.end());<span class="comment">//v2是v1的一个副本，若v1.size（）  &gt;v2.size()则赋值后v2.size()被扩充为v1.size()。</span></span><br><span class="line"><span class="built_in">vector</span>&lt; typeName &gt; v3(n,i);<span class="comment">//v3包括n个值为i的typeName类型元素</span></span><br><span class="line"><span class="built_in">vector</span>&lt; typeName &gt; v4(n); <span class="comment">//v4含有n个值为0的元素</span></span><br><span class="line"><span class="keyword">int</span> a[<span class="number">4</span>]=&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>&#125;; <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v5(a,a+<span class="number">5</span>);<span class="comment">//v5的size为5，v5被初始化为a的5个值。后一个指针要指向将被拷贝的末元素的下一位置。</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v6(v5);<span class="comment">//v6是v5的拷贝</span></span><br><span class="line"><span class="built_in">vector</span>&lt; 类型 &gt; 标识符（最大容量，初始全部值）</span><br></pre></td></tr></table></figure>
<p>Vector的基本函数</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>push_back 在数组的最后添加一个数据</span><br><span class="line"><span class="number">2.</span>pop_back 去掉数组的最后一个数据</span><br><span class="line"><span class="number">3.</span>at 得到编号位置的数据</span><br><span class="line"><span class="number">4.b</span>egin 得到数组头的指针</span><br><span class="line"><span class="number">5.</span>end 得到数组的最后一个单元+<span class="number">1</span>的指针</span><br><span class="line"><span class="number">6</span>．front 得到数组头的引用</span><br><span class="line"><span class="number">7.b</span>ack 得到数组的最后一个单元的引用</span><br><span class="line"><span class="number">8.</span>max_size 得到<span class="built_in">vector</span>最大可以是多大</span><br><span class="line"><span class="number">9.</span>capacity 当前<span class="built_in">vector</span>分配的大小</span><br><span class="line"><span class="number">10.</span>size 当前使用数据的大小</span><br><span class="line"><span class="number">11.</span>resize 改变当前使用数据的大小，如果它比当前使用的大，者填充默认值</span><br><span class="line"><span class="number">12.</span>reserve 改变当前vecotr所分配空间的大小</span><br><span class="line"><span class="number">13.</span>erase 删除指针指向的数据项</span><br><span class="line"><span class="number">14.</span>clear 清空当前的<span class="built_in">vector</span></span><br><span class="line"><span class="number">15.</span>rbegin 将<span class="built_in">vector</span>反转后的开始指针返回(其实就是原来的end<span class="number">-1</span>)</span><br><span class="line"><span class="number">16.</span>rend 将<span class="built_in">vector</span>反转构的结束指针返回(其实就是原来的begin<span class="number">-1</span>)</span><br><span class="line"><span class="number">17.</span>empty 判断<span class="built_in">vector</span>是否为空</span><br><span class="line"><span class="number">18.</span>swap 与另一个<span class="built_in">vector</span>交换数据</span><br></pre></td></tr></table></figure>
<p>2.to_string</p>
<p><code>#include &lt;string&gt;</code></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">to_string</span> <span class="params">(<span class="keyword">int</span> val)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">to_string</span> <span class="params">(<span class="keyword">long</span> val)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">to_string</span> <span class="params">(<span class="keyword">long</span> <span class="keyword">long</span> val)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">to_string</span> <span class="params">(<span class="keyword">unsigned</span> val)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">to_string</span> <span class="params">(<span class="keyword">unsigned</span> <span class="keyword">long</span> val)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">to_string</span> <span class="params">(<span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> val)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">to_string</span> <span class="params">(<span class="keyword">float</span> val)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">to_string</span> <span class="params">(<span class="keyword">double</span> val)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">to_string</span> <span class="params">(<span class="keyword">long</span> <span class="keyword">double</span> val)</span></span>;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/09/eat/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/09/eat/" itemprop="url">eat</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-09T11:10:19+08:00">
                2018-11-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="吃饭饭"><a href="#吃饭饭" class="headerlink" title="吃饭饭"></a><strong>吃饭饭</strong></h1>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/09/leetcode155/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/09/leetcode155/" itemprop="url">【leetcode】155：Min Stack</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-09T10:47:03+08:00">
                2018-11-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="最小栈"><a href="#最小栈" class="headerlink" title="最小栈"></a>最小栈</h1><p><strong>难度：Easy</strong></p>
<h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><p>设计一个支持 push，pop，top 操作，并能在常数时间内检索到最小元素的栈。</p>
<ul>
<li>push(x) – 将元素 x 推入栈中。</li>
<li>pop() – 删除栈顶的元素。</li>
<li>top() – 获取栈顶元素。</li>
<li>getMin() – 检索（retrievie）栈中的最小元素。</li>
</ul>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MinStack minStack = <span class="keyword">new</span> MinStack();</span><br><span class="line">minStack.push(<span class="number">-2</span>);</span><br><span class="line">minStack.push(<span class="number">0</span>);</span><br><span class="line">minStack.push(<span class="number">-3</span>);</span><br><span class="line">minStack.getMin();   --&gt; Returns <span class="number">-3.</span></span><br><span class="line">minStack.pop();</span><br><span class="line">minStack.top();      --&gt; Returns <span class="number">0.</span></span><br><span class="line">minStack.getMin();   --&gt; Returns <span class="number">-2.</span></span><br></pre></td></tr></table></figure>
<h2 id="解法一"><a href="#解法一" class="headerlink" title="解法一"></a>解法一</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MinStack</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">/** initialize your data structure here. */</span></span><br><span class="line">    MinStack() &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        s1.push(x);</span><br><span class="line">        <span class="keyword">if</span> (s2.empty() || x &lt;= s2.top()) s2.push(x);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (s1.top() == s2.top()) s2.pop();</span><br><span class="line">        s1.pop();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">top</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> s1.top();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getMin</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> s2.top();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; s1, s2;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>用两个栈，s1来按顺序存储push进来的数据，s2的栈顶用来存最小值</p>
<h3 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h3><p>stack(堆栈）是一个容器的改编，它实现了一个先进后出的数据结构（FILO）。<br>定义stack对象的示例如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; s1;</span><br><span class="line"><span class="built_in">stack</span>&lt;<span class="built_in">string</span>&gt; s2;</span><br></pre></td></tr></table></figure></p>
<p>stack的基本操作如下：</p>
<table>
<thead>
<tr>
<th>函数名</th>
<th>功能</th>
<th>复杂度</th>
</tr>
</thead>
<tbody>
<tr>
<td>size()</td>
<td>返回栈的元素数</td>
<td>O(1)</td>
</tr>
<tr>
<td>top()</td>
<td>返回栈顶的元素</td>
<td>O(1)</td>
</tr>
<tr>
<td>pop()</td>
<td>从栈中取出并删除元素</td>
<td>O(1)</td>
</tr>
<tr>
<td>push(x)</td>
<td>向栈中添加元素x</td>
<td>O(1)</td>
</tr>
<tr>
<td>empty()</td>
<td>在栈为空时返回true</td>
<td>O(1)</td>
</tr>
</tbody>
</table>
<h2 id="解法二"><a href="#解法二" class="headerlink" title="解法二"></a>解法二</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MinStack</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">/** initialize your data structure here. */</span></span><br><span class="line">    MinStack() &#123;</span><br><span class="line">        min_val = INT_MAX;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (x &lt;= min_val) &#123;</span><br><span class="line">            st.push(min_val);</span><br><span class="line">            min_val = x;</span><br><span class="line">        &#125;</span><br><span class="line">        st.push(x);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> t = st.top(); st.pop();</span><br><span class="line">        <span class="keyword">if</span> (t == min_val) &#123;</span><br><span class="line">            min_val = st.top(); st.pop();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">top</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> st.top();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getMin</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> min_val;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> min_val;</span><br><span class="line">    <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; st;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="知识点-1"><a href="#知识点-1" class="headerlink" title="知识点"></a>知识点</h3><p>常量INT_MAX 表示最大整数 2^31-1，INT_MIN表示最小整数-2^31</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/09/Fast R-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/09/Fast R-CNN/" itemprop="url">Fast R-CNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-09T09:49:31+08:00">
                2018-11-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>paper：<br><a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="noopener"><strong>Fast R-CNN</strong> -arXiv:1504 ICCV2015</a></p>
<hr>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>R-CNN之后，RGB大神又单枪匹马干出了Fast R-CNN。相较于前者，Fast R-CNN更加Deep Learning化了，一是只对整幅图进行一次特征提取；二是将bounding box的分类和回归联合起来，进行多任务的训练。</p>
<hr>
<h1 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h1><p><img src="/2018/11/09/Fast R-CNN/1.png" alt="1539947950822"></p>
<p>Faster R-CNN的流程如下：</p>
<ol>
<li>和R-CNN一样，用selective search算法在输入图片上提取约2000个候选框。</li>
<li>将图片输入CNN网络中，得到特征图（feature map）。</li>
<li>对于每个候选框，都可以在特征图上找到与其相对应的特征框，然后用ROI池化层（region of interest pooling layer）将每个特征框池化到固定的大小。</li>
<li>将特征框输入全连接层（FC layers）得到特征向量。</li>
<li>将特征向量分别通过两个不同的全连接层，其中一个输出softmax的分类得分，另一个输出bounding box的regression。</li>
<li>利用窗口得分分别对每一类物体进行非极大值抑制剔除重叠建议框，最终得到每个类别中回归修正后的得分最高的窗口。 </li>
</ol>
<h2 id="1-RoI-pooling-layer"><a href="#1-RoI-pooling-layer" class="headerlink" title="1.RoI pooling layer"></a>1.RoI pooling layer</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">像AlexNet CNN等网络在提取特征过程中对图像的大小并无要求，只是在提取完特征进行全连接操作的时候才需要固定特征尺寸，利用这一点，Fast R-CNN可输入任意size图片，并在全连接操作前加入RoI池化层，将建议框对应特征图中的特征框池化到H×W 的size，以便满足后续操作对size的要求</span><br></pre></td></tr></table></figure>
<p>RoI池化层使用max pooling 将特征框固定为HxW大小。若特征框大小为h×w，则设定每个子窗口大小为h/H×w/W，然后对每个子窗口采用max pooling下采样操作，每个子窗口只取一个最大值，则特征框最终池化为H×W的大小。 </p>
<h2 id="2-训练"><a href="#2-训练" class="headerlink" title="2.训练"></a>2.训练</h2><h3 id="2-1预训练"><a href="#2-1预训练" class="headerlink" title="2.1预训练"></a>2.1预训练</h3><p>采用了AlexNet、VGG_CNN_M_1024 、VGG-16三种网络在ImageNet上进行预训练。之后，对网络进行了三处修改：</p>
<ol>
<li>最后一层max pooling 改为 RoI pooling</li>
<li>最后的fully connected layer 和softmax替换为两个子网络，其一是全连接层加K+1个分类的softmax，其二是全连接层加bounding box回归器</li>
<li>改为双输入，即图像和其对应的region proposal</li>
</ol>
<h3 id="2-2-检测任务上的微调"><a href="#2-2-检测任务上的微调" class="headerlink" title="2.2 检测任务上的微调"></a>2.2 检测任务上的微调</h3><h4 id="多任务损失"><a href="#多任务损失" class="headerlink" title="多任务损失"></a>多任务损失</h4><p>Fast R-CNN有两个输出，第一个是K+1个类别的离散概率分布p=( p_{0},  …, p_{K})，第二个是bounding-box regression的offset</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Pan Sicheng</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Pan Sicheng</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
