<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="Good Good Study">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Good Good Study">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Good Good Study">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Good Good Study</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Good Good Study</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/28/segmentation-paper/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/28/segmentation-paper/" itemprop="url">segmentation-paper</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-28T09:34:08+08:00">
                2019-03-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/28/super-resolution-paper/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/28/super-resolution-paper/" itemprop="url">super-resolution-paper</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-28T09:33:55+08:00">
                2019-03-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/28/linux/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/28/linux/" itemprop="url">linux</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-28T09:04:58+08:00">
                2019-03-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>zjuvpn安装</strong></p>
<p><a href="https://www.cc98.org/topic/2323871" target="_blank" rel="noopener">https://www.cc98.org/topic/2323871</a></p>
<p>1.删除原来的xl2tpd包：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg --purge xl2tpd</span><br></pre></td></tr></table></figure></p>
<p>2.下载：<br><a href="https://pan.baidu.com/s/1eRNQwng#list/path=%2F" target="_blank" rel="noopener">https://pan.baidu.com/s/1eRNQwng#list/path=%2F</a></p>
<p>3.安装：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg -i xl2tpd_1.1.12-zju2_i386.deb</span><br></pre></td></tr></table></figure></p>
<p>报错：没有iproute 所以要先装一个：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install iproute</span><br></pre></td></tr></table></figure></p>
<p>4.配置:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vpn-connect -c</span><br></pre></td></tr></table></figure></p>
<p>按照提示操作, 注意用户名 学号后面要加@a</p>
<p>5.连接:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vpn-connect</span><br></pre></td></tr></table></figure></p>
<p>6.断开:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vpn-connect -d</span><br></pre></td></tr></table></figure></p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/25/high-dynamic-range-paper/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/25/high-dynamic-range-paper/" itemprop="url">High Dynamic Range Paper</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-25T20:57:15+08:00">
                2019-03-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Using-a-series-of-low-dynamic-range-images-at-different-exposure"><a href="#Using-a-series-of-low-dynamic-range-images-at-different-exposure" class="headerlink" title="Using a series of low dynamic range images at different exposure"></a>Using a series of low dynamic range images at different exposure</h1><p>Generally, this problem can be broken down into two stages: 1) aligning the input LDR images and 2) merging the aligned images into an HDR image.</p>
<p>This method produces spectacular images for tripod mounted cameras and static scenes, but generates results with ghosting artifacts when the scene is dynamic or the camera is hand-held.</p>
<hr>
<h2 id="Deep-High-Dynamic-Range-Imaging-of-Dynamic-Scenes-SIGGRAPH2017"><a href="#Deep-High-Dynamic-Range-Imaging-of-Dynamic-Scenes-SIGGRAPH2017" class="headerlink" title="Deep High Dynamic Range Imaging of Dynamic Scenes - SIGGRAPH2017"></a>Deep High Dynamic Range Imaging of Dynamic Scenes - SIGGRAPH2017</h2><p>-the artifacts of the alignment can be significantly reduced during merging</p>
<p>-<em>Preprocessing the Input LDR Images:</em> </p>
<p>If the LDR images are not in the RAW format, we first linearize them using the camera response function (CRF), then apply gamma correction (γ = 2.2). The gamma correction basically maps the images into a domain that is closer to what we perceive with our eyes.</p>
<p>-<em>Alignment:</em> </p>
<p>Produce aligned images by registering the images with low (Z1) and high (Z3) exposures to the reference image Z2 using tranditional method. (optical flow)</p>
<p>-<em>HDR Merge:</em></p>
<p>1)<em>Model</em>:<br><img src="/2019/03/25/high-dynamic-range-paper/1.png" alt=""><br><img src="/2019/03/25/high-dynamic-range-paper/2.png" alt=""></p>
<p>2)<em>Loss Function</em>:</p>
<p>Since HDR images are usually displayed after <em>tonemapping</em>, we propose to compute our loss function between the tonemapped estimated and ground truth HDR images. We propose to use μ-law, a commonly-used range compressor in audio processing, which is differentiable.<br><img src="/2019/03/25/high-dynamic-range-paper/3.png" alt=""></p>
<p>we train the learning system by minimizing the L2 distance of the tonemapped estimated and<br>ground truth HDR images defined as:<br><img src="/2019/03/25/high-dynamic-range-paper/4.png" alt=""></p>
<hr>
<h2 id="Deep-High-Dynamic-Range-Imaging-with-Large-Foreground-Motions-ECCV2018"><a href="#Deep-High-Dynamic-Range-Imaging-with-Large-Foreground-Motions-ECCV2018" class="headerlink" title="Deep High Dynamic Range Imaging with Large Foreground Motions - ECCV2018"></a>Deep High Dynamic Range Imaging with Large Foreground Motions - ECCV2018</h2><p>-CNNs have been demonstrated to have the ability to learn misalignment and hallucinate missing details</p>
<p>-Three advantage: 1) trained end-to-end without optical flow alignment. 2)can hallucinate plausible details that are totally missing or their presence is extremely weak in all LDR inputs. 3) the same framework can be easily extended to more LDR inputs, and possibly with any specified reference image.</p>
<p>-<em>Network Architecture</em><br><img src="/2019/03/25/high-dynamic-range-paper/11.png" alt=""><br>We separate the first two layers as encoders for each exposure inputs. After extracting the features, the network learns to merge them, mostly in the middle layers, and to decode them into an HDR output, mostly in the last few layers.</p>
<p>-<em>Processing Pipeline and Loss Function</em></p>
<p>Given a stack of LDR images, if they are not in RAW format, we first linearize the images using the estimated inverse of Camera Response Function (CRF), which is often referred to as radiometric calibration. We then apply gamma correction to produce the input to our system.</p>
<p>We first map LDRs to H = {H1;H2;H3} in the HDR domain, using simple gamma encoding:<br><img src="/2019/03/25/high-dynamic-range-paper/12.png" alt=""><br>where ti is the exposure time of image Ii. We then concatenate I and H channel-wise into a 6-channel input and feed it directly to the network. The LDRs facilitate the detection of misalignments and saturation, while the exposure-adjusted HDRs improve the robustness of the network across LDRs with various exposure levels.</p>
<p>Tonemapping function and loss function are the same as the previous paper.<br><img src="/2019/03/25/high-dynamic-range-paper/13.png" alt=""></p>
<p>-<em>Data Preparation</em></p>
<p>First align the background using simple homography transformation by <em>homography transformation</em>. Without it, we found that our network tends to produce blurry edges where background is largely misaligned.</p>
<p>Crop the images into 256x256 patches with a stride of 64. To keep the training focused on foreground motions, we detect large motion patches by thresholding the structural similarity<br>between different exposure shots, and replicate these patches in the training set.</p>
<h1 id="Using-single-low-dynamic-range-image"><a href="#Using-single-low-dynamic-range-image" class="headerlink" title="Using single low dynamic range image"></a>Using single low dynamic range image</h1><h2 id="HDR-image-reconstruction-from-a-single-exposure-using-deep-CNNs-1710"><a href="#HDR-image-reconstruction-from-a-single-exposure-using-deep-CNNs-1710" class="headerlink" title="HDR image reconstruction from a single exposure using deep CNNs - 1710"></a>HDR image reconstruction from a single exposure using deep CNNs - 1710</h2><p>-Estimating missing information in bright image parts, such as highlights, lost due to saturation of the camera sensor<br><img src="/2019/03/25/high-dynamic-range-paper/21.png" alt=""></p>
<hr>
<h2 id="ExpandNet-A-Deep-Convolutional-Neural-Network-for-High-Dynamic-Range-Expansion-from-Low-Dynamic-Range-Content-EUROGRAPHICS-2018"><a href="#ExpandNet-A-Deep-Convolutional-Neural-Network-for-High-Dynamic-Range-Expansion-from-Low-Dynamic-Range-Content-EUROGRAPHICS-2018" class="headerlink" title="ExpandNet: A Deep Convolutional Neural Network for High Dynamic Range Expansion from Low Dynamic Range Content - EUROGRAPHICS 2018"></a>ExpandNet: A Deep Convolutional Neural Network for High Dynamic Range Expansion from Low Dynamic Range Content - EUROGRAPHICS 2018</h2><p>-Designed to avoid upsampling of downsampled features, in an attempt to reduce blocking and/or haloing artefacts that may arise from more straightforward approaches.</p>
<p>-It is argued that upsampling, especially the frequently used deconvolutional layers, cause checkerboard artefacts. Furthermore, upsampling may cause unwanted information bleeding in areas where context is missing, for example large overexposed areas.</p>
<p>-The local branch handling local detail, the dilation branch for medium level detail, and a global branch accounting for higher level image-wide features<br><img src="/2019/03/25/high-dynamic-range-paper/31.png" alt=""></p>
<p>-<em>Loss Function</em></p>
<p>The L1 distance is chosen for this problem since the more frequently used L2 distance was found to cause blurry results for images. An additional cosine similarity term is added to ensure color correctness of the RGB vectors of each pixel.<br><img src="/2019/03/25/high-dynamic-range-paper/32.png" alt=""></p>
<p>Cosine similarity measures how close two vectors are by comparing the angle between them, not taking magnitude into account. For the context of this work, it ensures that each pixel points in the same direction of the three dimensional RGB space. It provides improved color stability, especially for low luminance values, which are frequent in HDR images, since slight variations in any of the RGB components of these low values do not contribute much to the L1 loss, but they may however cause noticeable color shifts.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/05/paper-summarization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/05/paper-summarization/" itemprop="url">paper_summarization</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-05T16:40:28+08:00">
                2019-03-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Segmentation"><a href="#Segmentation" class="headerlink" title="Segmentation"></a>Segmentation</h1><h2 id="Sematic-Segmentation"><a href="#Sematic-Segmentation" class="headerlink" title="Sematic Segmentation"></a>Sematic Segmentation</h2><p><strong>[FCN - CVPR2015]</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/01/23/pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/23/pytorch/" itemprop="url">pytorch</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-23T14:50:33+08:00">
                2019-01-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="view"><a href="#view" class="headerlink" title="view"></a>view</h2><h2 id="transpose"><a href="#transpose" class="headerlink" title="transpose"></a>transpose</h2><h2 id="contiguous"><a href="#contiguous" class="headerlink" title="contiguous"></a>contiguous</h2><h2 id="repeat"><a href="#repeat" class="headerlink" title="repeat"></a>repeat</h2><h2 id="squeeze"><a href="#squeeze" class="headerlink" title="squeeze"></a>squeeze</h2><h2 id="unsqueeze"><a href="#unsqueeze" class="headerlink" title="unsqueeze"></a>unsqueeze</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/21/leetcode771/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/21/leetcode771/" itemprop="url">【leetcode】771：Jewels and Stones</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-21T10:43:02+08:00">
                2018-12-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="771-宝石与石头"><a href="#771-宝石与石头" class="headerlink" title="771 宝石与石头"></a>771 宝石与石头</h1><p><strong>难度：Easy</strong></p>
<h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><p>给定字符串J 代表石头中宝石的类型，和字符串 S代表你拥有的石头。 S 中每个字符代表了一种你拥有的石头的类型，你想知道你拥有的石头中有多少是宝石。</p>
<p>J 中的字母不重复，J 和 S中的所有字符都是字母。字母区分大小写，因此”a”和”A”是不同类型的石头。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: J = &quot;aA&quot;, S = &quot;aAAbbbb&quot;</span><br><span class="line">输出: 3</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: J = &quot;z&quot;, S = &quot;ZZ&quot;</span><br><span class="line">输出: 0</span><br></pre></td></tr></table></figure>
<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><ul>
<li><code>S</code> 和 <code>J</code> 最多含有50个字母。</li>
<li><code>J</code> 中的字符不重复。 </li>
</ul>
<h2 id="解法一"><a href="#解法一" class="headerlink" title="解法一"></a>解法一</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">numJewelsInStones</span><span class="params">(<span class="built_in">string</span> J, <span class="built_in">string</span> S)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">char</span> s : S) &#123;</span><br><span class="line">            <span class="keyword">for</span> (cahr j : J) &#123;</span><br><span class="line">                <span class="keyword">if</span> (s == j) &#123;</span><br><span class="line">                    ++res;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="解法二"><a href="#解法二" class="headerlink" title="解法二"></a>解法二</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">numJewelsInStones</span><span class="params">(<span class="built_in">string</span> J, <span class="built_in">string</span> S)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">unordered_set</span>&lt;<span class="keyword">char</span>&gt; s;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">char</span> c : J) s.insert(c);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">char</span> c : S) &#123;</span><br><span class="line">            <span class="keyword">if</span> (s.count(c)) ++res;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>用HashSet来优化时间复杂度，将珠宝字符串J中的所有字符都放入HashSet中，然后遍历石头字符串中的每个字符，到HashSet中查找是否存在，存在的话计数器自增1即可。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/20/caffe/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/20/caffe/" itemprop="url">Caffe</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-20T10:41:48+08:00">
                2018-12-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Image-Classification-and-Filter-Visualization"><a href="#Image-Classification-and-Filter-Visualization" class="headerlink" title="Image Classification and Filter Visualization"></a><a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/00-classification.ipynb" target="_blank" rel="noopener">Image Classification and Filter Visualization</a></h2><p>Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.</p>
<p><strong><em>set CPU mode and load net for test</em></strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">caffe.set_mode_cpu()</span><br><span class="line"></span><br><span class="line">net = caffe.Net(model_def,      <span class="comment"># defines the structure of the model</span></span><br><span class="line">                model_weights,  <span class="comment"># contains the trained weights</span></span><br><span class="line">                caffe.TEST)     <span class="comment"># use test mode (e.g., don't perform dropout)</span></span><br></pre></td></tr></table></figure>
<p><strong><em>input preprocessing</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Set up input preprocessing. (We&apos;ll use Caffe&apos;s caffe.io.Transformer to do this, but this step is independent of other parts of Caffe, so any custom preprocessing code may be used).</span><br><span class="line"></span><br><span class="line">Our default CaffeNet is configured to take images in BGR format. Values are expected to start in the range [0, 255] and then have the mean ImageNet pixel value subtracted from them. In addition, the channel dimension is expected as the first (outermost) dimension.</span><br><span class="line"></span><br><span class="line">As matplotlib will load images with values in the range [0, 1] in RGB format with the channel as the innermost dimension, we are arranging for the needed transformations here.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create transformer for the input called 'data'</span></span><br><span class="line">transformer = caffe.io.Transformer(&#123;<span class="string">'data'</span>: net.blobs[<span class="string">'data'</span>].data.shape&#125;)</span><br><span class="line"></span><br><span class="line">transformer.set_transpose(<span class="string">'data'</span>, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))  <span class="comment"># move image channels to outermost dimension</span></span><br><span class="line">transformer.set_mean(<span class="string">'data'</span>, mu)            <span class="comment"># subtract the dataset-mean value in each channel</span></span><br><span class="line">transformer.set_raw_scale(<span class="string">'data'</span>, <span class="number">255</span>)      <span class="comment"># rescale from [0, 1] to [0, 255]</span></span><br><span class="line">transformer.set_channel_swap(<span class="string">'data'</span>, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>))  <span class="comment"># swap channels from RGB to BGR</span></span><br></pre></td></tr></table></figure>
<p><strong><em>set the size of the input</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set the size of the input (we can skip this if we're happy</span></span><br><span class="line"><span class="comment">#  with the default; we can also change it later, e.g., for different batch sizes)</span></span><br><span class="line">net.blobs[<span class="string">'data'</span>].reshape(<span class="number">50</span>,        <span class="comment"># batch size</span></span><br><span class="line">                          <span class="number">3</span>,         <span class="comment"># 3-channel (BGR) images</span></span><br><span class="line">                          <span class="number">227</span>, <span class="number">227</span>)  <span class="comment"># image size is 227x227</span></span><br></pre></td></tr></table></figure></p>
<p><strong><em>load an image and perform the preprocessing</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image = caffe.io.load_image(caffe_root + <span class="string">'examples/images/cat.jpg'</span>)</span><br><span class="line">transformed_image = transformer.preprocess(<span class="string">'data'</span>, image)</span><br></pre></td></tr></table></figure></p>
<p><strong><em>classify</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># copy the image data into the memory allocated for the net</span></span><br><span class="line">net.blobs[<span class="string">'data'</span>].data[...] = transformed_image</span><br><span class="line"></span><br><span class="line"><span class="comment">### perform classification</span></span><br><span class="line">output = net.forward()</span><br><span class="line"></span><br><span class="line">output_prob = output[<span class="string">'prob'</span>][<span class="number">0</span>]  <span class="comment"># the output probability vector for the first image in the batch</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">'predicted class is:'</span>, output_prob.argmax()</span><br></pre></td></tr></table></figure></p>
<p><strong><em>top5</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sort top five predictions from softmax output</span></span><br><span class="line">top_inds = output_prob.argsort()[::<span class="number">-1</span>][:<span class="number">5</span>]  <span class="comment"># reverse sort and take five largest items</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">'probabilities and labels:'</span></span><br><span class="line">zip(output_prob[top_inds], labels[top_inds])</span><br></pre></td></tr></table></figure></p>
<p><strong><em>switch to GPU</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">caffe.set_device(<span class="number">0</span>)  <span class="comment"># if we have multiple GPUs, pick the first one</span></span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line">net.forward()  <span class="comment"># run once before timing to set up memory</span></span><br></pre></td></tr></table></figure></p>
<p><strong><em>show the output shape of each layers</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> layer_name, blob <span class="keyword">in</span> net.blobs.iteritems():</span><br><span class="line">    <span class="keyword">print</span> layer_name + <span class="string">'\t'</span> + str(blob.data.shape)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">data	(50, 3, 227, 227)</span><br><span class="line">conv1	(50, 96, 55, 55)</span><br><span class="line">pool1	(50, 96, 27, 27)</span><br><span class="line">norm1	(50, 96, 27, 27)</span><br><span class="line">conv2	(50, 256, 27, 27)</span><br><span class="line">pool2	(50, 256, 13, 13)</span><br><span class="line">norm2	(50, 256, 13, 13)</span><br><span class="line">conv3	(50, 384, 13, 13)</span><br><span class="line">conv4	(50, 384, 13, 13)</span><br><span class="line">conv5	(50, 256, 13, 13)</span><br><span class="line">pool5	(50, 256, 6, 6)</span><br><span class="line">fc6		(50, 4096)</span><br><span class="line">fc7		(50, 4096)</span><br><span class="line">fc8		(50, 1000)</span><br><span class="line">prob	(50, 1000)</span><br></pre></td></tr></table></figure>
<p><strong><em>show the parameter shape</em></strong><br>We need to index the resulting values with either [0] for weights or [1] for biases.<br>The param shapes typically have the form <code>(output_channels, input_channels, filter_height, filter_width)</code>(for the weights) and the 1-dimensional shape <code>(output_channels,)</code>(for the biases).<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> layer_name, param <span class="keyword">in</span> net.params.iteritems():</span><br><span class="line">    <span class="keyword">print</span> layer_name + <span class="string">'\t'</span> + str(param[<span class="number">0</span>].data.shape), str(param[<span class="number">1</span>].data.shape)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">conv1	(96, 3, 11, 11) (96,)</span><br><span class="line">conv2	(256, 48, 5, 5) (256,)</span><br><span class="line">conv3	(384, 256, 3, 3) (384,)</span><br><span class="line">conv4	(384, 192, 3, 3) (384,)</span><br><span class="line">conv5	(256, 192, 3, 3) (256,)</span><br><span class="line">fc6	(4096, 9216) (4096,)</span><br><span class="line">fc7	(4096, 4096) (4096,)</span><br><span class="line">fc8	(1000, 4096) (1000,)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Learning-LeNet"><a href="#Learning-LeNet" class="headerlink" title="Learning LeNet"></a><a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/01-learning-lenet.ipynb" target="_blank" rel="noopener">Learning LeNet</a></h2><p>Define, train, and test the classic LeNet with the Python interface.</p>
<p><strong><em>create LeNet</em></strong></p>
<p>We’ll need two external files to help out:</p>
<ul>
<li>the net <code>prototxt</code>, defining the architecture and pointing to the train/test data</li>
<li>the solver <code>prototxt</code>, defining the learning parameters</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> caffe <span class="keyword">import</span> layers <span class="keyword">as</span> L, params <span class="keyword">as</span> P</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lenet</span><span class="params">(lmdb, batch_size)</span>:</span></span><br><span class="line">    <span class="comment"># our version of LeNet: a series of linear and simple nonlinear transformations</span></span><br><span class="line">    n = caffe.NetSpec()</span><br><span class="line">    </span><br><span class="line">    n.data, n.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,transform_param=dict(scale=<span class="number">1.</span>/<span class="number">255</span>), ntop=<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    n.conv1 = L.Convolution(n.data, kernel_size=<span class="number">5</span>, num_output=<span class="number">20</span>, weight_filler=dict(type=<span class="string">'xavier'</span>))</span><br><span class="line">    n.pool1 = L.Pooling(n.conv1, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, pool=P.Pooling.MAX)</span><br><span class="line">    n.conv2 = L.Convolution(n.pool1, kernel_size=<span class="number">5</span>, num_output=<span class="number">50</span>, weight_filler=dict(type=<span class="string">'xavier'</span>))</span><br><span class="line">    n.pool2 = L.Pooling(n.conv2, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, pool=P.Pooling.MAX)</span><br><span class="line">    n.fc1 =   L.InnerProduct(n.pool2, num_output=<span class="number">500</span>, weight_filler=dict(type=<span class="string">'xavier'</span>))</span><br><span class="line">    n.relu1 = L.ReLU(n.fc1, in_place=<span class="keyword">True</span>)</span><br><span class="line">    n.score = L.InnerProduct(n.relu1, num_output=<span class="number">10</span>, weight_filler=dict(type=<span class="string">'xavier'</span>))</span><br><span class="line">    n.loss =  L.SoftmaxWithLoss(n.score, n.label)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> n.to_proto()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'mnist/lenet_auto_train.prototxt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(str(lenet(<span class="string">'mnist/mnist_train_lmdb'</span>, <span class="number">64</span>)))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'mnist/lenet_auto_test.prototxt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(str(lenet(<span class="string">'mnist/mnist_test_lmdb'</span>, <span class="number">100</span>)))</span><br></pre></td></tr></table></figure>
<p>The net has been written to disk in a more verbose but human-readable serialization format using Google’s protobuf library. You can read, write, and modify this description directly. Let’s take a look at the train net. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"data"</span></span><br><span class="line">  type: <span class="string">"Data"</span></span><br><span class="line">  top: <span class="string">"data"</span></span><br><span class="line">  top: <span class="string">"label"</span></span><br><span class="line">  transform_param &#123;</span><br><span class="line">    scale: <span class="number">0.00392156862745</span></span><br><span class="line">  &#125;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    source: <span class="string">"mnist/mnist_train_lmdb"</span></span><br><span class="line">    batch_size: <span class="number">64</span></span><br><span class="line">    backend: LMDB</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv1"</span></span><br><span class="line">  type: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"data"</span></span><br><span class="line">  top: <span class="string">"conv1"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">20</span></span><br><span class="line">    kernel_size: <span class="number">5</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool1"</span></span><br><span class="line">  type: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"conv1"</span></span><br><span class="line">  top: <span class="string">"pool1"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: <span class="number">2</span></span><br><span class="line">    stride: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv2"</span></span><br><span class="line">  type: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"pool1"</span></span><br><span class="line">  top: <span class="string">"conv2"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">50</span></span><br><span class="line">    kernel_size: <span class="number">5</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool2"</span></span><br><span class="line">  type: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"conv2"</span></span><br><span class="line">  top: <span class="string">"pool2"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: <span class="number">2</span></span><br><span class="line">    stride: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"fc1"</span></span><br><span class="line">  type: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"pool2"</span></span><br><span class="line">  top: <span class="string">"fc1"</span></span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">500</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu1"</span></span><br><span class="line">  type: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"fc1"</span></span><br><span class="line">  top: <span class="string">"fc1"</span></span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"score"</span></span><br><span class="line">  type: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"fc1"</span></span><br><span class="line">  top: <span class="string">"score"</span></span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">10</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"loss"</span></span><br><span class="line">  type: <span class="string">"SoftmaxWithLoss"</span></span><br><span class="line">  bottom: <span class="string">"score"</span></span><br><span class="line">  bottom: <span class="string">"label"</span></span><br><span class="line">  top: <span class="string">"loss"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Now let’s see the learning parameters, which are also written as a <code>prototxt</code> file (already provided on disk). We’re using SGD with momentum, weight decay, and a specific learning rate schedule<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The train/test net protocol buffer definition</span></span><br><span class="line">train_net: <span class="string">"mnist/lenet_auto_train.prototxt"</span></span><br><span class="line">test_net: <span class="string">"mnist/lenet_auto_test.prototxt"</span></span><br><span class="line"><span class="comment"># test_iter specifies how many forward passes the test should carry out.</span></span><br><span class="line"><span class="comment"># In the case of MNIST, we have test batch size 100 and 100 test iterations,</span></span><br><span class="line"><span class="comment"># covering the full 10,000 testing images.</span></span><br><span class="line">test_iter: <span class="number">100</span></span><br><span class="line"><span class="comment"># Carry out testing every 500 training iterations.</span></span><br><span class="line">test_interval: <span class="number">500</span></span><br><span class="line"><span class="comment"># The base learning rate, momentum and the weight decay of the network.</span></span><br><span class="line">base_lr: <span class="number">0.01</span></span><br><span class="line">momentum: <span class="number">0.9</span></span><br><span class="line">weight_decay: <span class="number">0.0005</span></span><br><span class="line"><span class="comment"># The learning rate policy</span></span><br><span class="line">lr_policy: <span class="string">"inv"</span></span><br><span class="line">gamma: <span class="number">0.0001</span></span><br><span class="line">power: <span class="number">0.75</span></span><br><span class="line"><span class="comment"># Display every 100 iterations</span></span><br><span class="line">display: <span class="number">100</span></span><br><span class="line"><span class="comment"># The maximum number of iterations</span></span><br><span class="line">max_iter: <span class="number">10000</span></span><br><span class="line"><span class="comment"># snapshot intermediate results</span></span><br><span class="line">snapshot: <span class="number">5000</span></span><br><span class="line">snapshot_prefix: <span class="string">"mnist/lenet"</span></span><br></pre></td></tr></table></figure></p>
<p><strong><em>loading and checking the slover</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">caffe.set_device(<span class="number">0</span>)</span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line"></span><br><span class="line"><span class="comment">### load the solver and create train and test nets</span></span><br><span class="line">solver = <span class="keyword">None</span>  <span class="comment"># ignore this workaround for lmdb data (can't instantiate two solvers on the same data)</span></span><br><span class="line">solver = caffe.SGDSolver(<span class="string">'mnist/lenet_auto_solver.prototxt'</span>)</span><br></pre></td></tr></table></figure></p>
<p><em>check</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># each output is (batch size, feature dim, spatial dim)</span></span><br><span class="line">[(k, v.data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> solver.net.blobs.items()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># just print the weight sizes (we'll omit the biases)</span></span><br><span class="line">[(k, v[<span class="number">0</span>].data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> solver.net.params.items()]</span><br><span class="line">Out[<span class="number">9</span>]:</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">solver.net.forward()  <span class="comment"># train net</span></span><br><span class="line">solver.test_nets[<span class="number">0</span>].forward()  <span class="comment"># test net (there can be more than one)</span></span><br></pre></td></tr></table></figure>
<p><strong><em>Writing a custom training loop</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">niter = <span class="number">200</span></span><br><span class="line">test_interval = <span class="number">25</span></span><br><span class="line"><span class="comment"># losses will also be stored in the log</span></span><br><span class="line">train_loss = zeros(niter)</span><br><span class="line">test_acc = zeros(int(np.ceil(niter / test_interval)))</span><br><span class="line">output = zeros((niter, <span class="number">8</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># the main solver loop</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(niter):</span><br><span class="line">    solver.step(<span class="number">1</span>)  <span class="comment"># SGD by Caffe</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store the train loss</span></span><br><span class="line">    train_loss[it] = solver.net.blobs[<span class="string">'loss'</span>].data</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store the output on the first test batch</span></span><br><span class="line">    <span class="comment"># (start the forward pass at conv1 to avoid loading new data)</span></span><br><span class="line">    solver.test_nets[<span class="number">0</span>].forward(start=<span class="string">'conv1'</span>)</span><br><span class="line">    output[it] = solver.test_nets[<span class="number">0</span>].blobs[<span class="string">'score'</span>].data[:<span class="number">8</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># run a full test every so often</span></span><br><span class="line">    <span class="comment"># (Caffe can also do this for us and write to a log, but we show here</span></span><br><span class="line">    <span class="comment">#  how to do it directly in Python, where more complicated things are easier.)</span></span><br><span class="line">    <span class="keyword">if</span> it % test_interval == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'Iteration'</span>, it, <span class="string">'testing...'</span></span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> test_it <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">            solver.test_nets[<span class="number">0</span>].forward()</span><br><span class="line">            correct += sum(solver.test_nets[<span class="number">0</span>].blobs[<span class="string">'score'</span>].data.argmax(<span class="number">1</span>)</span><br><span class="line">                           == solver.test_nets[<span class="number">0</span>].blobs[<span class="string">'label'</span>].data)</span><br><span class="line">        test_acc[it // test_interval] = correct / <span class="number">1e4</span></span><br></pre></td></tr></table></figure></p>
<p><strong><em>define slover</em></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> caffe.proto <span class="keyword">import</span> caffe_pb2</span><br><span class="line">s = caffe_pb2.SolverParameter()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set a seed for reproducible experiments:</span></span><br><span class="line"><span class="comment"># this controls for randomization in training.</span></span><br><span class="line">s.random_seed = <span class="number">0xCAFFE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify locations of the train and (maybe) test networks.</span></span><br><span class="line">s.train_net = train_net_path</span><br><span class="line">s.test_net.append(test_net_path)</span><br><span class="line">s.test_interval = <span class="number">500</span>  <span class="comment"># Test after every 500 training iterations.</span></span><br><span class="line">s.test_iter.append(<span class="number">100</span>) <span class="comment"># Test on 100 batches each time we test.</span></span><br><span class="line"></span><br><span class="line">s.max_iter = <span class="number">10000</span>     <span class="comment"># no. of times to update the net (training iterations)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># EDIT HERE to try different solvers</span></span><br><span class="line"><span class="comment"># solver types include "SGD", "Adam", and "Nesterov" among others.</span></span><br><span class="line">s.type = <span class="string">"SGD"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the initial learning rate for SGD.</span></span><br><span class="line">s.base_lr = <span class="number">0.01</span>  <span class="comment"># EDIT HERE to try different learning rates</span></span><br><span class="line"><span class="comment"># Set momentum to accelerate learning by</span></span><br><span class="line"><span class="comment"># taking weighted average of current and previous updates.</span></span><br><span class="line">s.momentum = <span class="number">0.9</span></span><br><span class="line"><span class="comment"># Set weight decay to regularize and prevent overfitting</span></span><br><span class="line">s.weight_decay = <span class="number">5e-4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set `lr_policy` to define how the learning rate changes during training.</span></span><br><span class="line"><span class="comment"># This is the same policy as our default LeNet.</span></span><br><span class="line">s.lr_policy = <span class="string">'inv'</span></span><br><span class="line">s.gamma = <span class="number">0.0001</span></span><br><span class="line">s.power = <span class="number">0.75</span></span><br><span class="line"><span class="comment"># EDIT HERE to try the fixed rate (and compare with adaptive solvers)</span></span><br><span class="line"><span class="comment"># `fixed` is the simplest policy that keeps the learning rate constant.</span></span><br><span class="line"><span class="comment"># s.lr_policy = 'fixed'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the current training loss and accuracy every 1000 iterations.</span></span><br><span class="line">s.display = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Snapshots are files used to store networks we've trained.</span></span><br><span class="line"><span class="comment"># We'll snapshot every 5K iterations -- twice during training.</span></span><br><span class="line">s.snapshot = <span class="number">5000</span></span><br><span class="line">s.snapshot_prefix = <span class="string">'mnist/custom_net'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train on the GPU</span></span><br><span class="line">s.solver_mode = caffe_pb2.SolverParameter.GPU</span><br><span class="line"></span><br><span class="line"><span class="comment"># Write the solver to a temporary file and return its filename.</span></span><br><span class="line"><span class="keyword">with</span> open(solver_config_path, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(str(s))</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="Fine-tuning-for-Style-Recognition"><a href="#Fine-tuning-for-Style-Recognition" class="headerlink" title="Fine-tuning for Style Recognition"></a><a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/02-fine-tuning.ipynb" target="_blank" rel="noopener">Fine-tuning for Style Recognition</a></h2><p>Fine-tune the ImageNet-trained CaffeNet on new data.</p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/14/object_detection_paper_summarization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/14/object_detection_paper_summarization/" itemprop="url">Object Detection Paper Summarization</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-14T14:36:12+08:00">
                2018-12-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Basic-Detection-Framework"><a href="#Basic-Detection-Framework" class="headerlink" title="Basic Detection Framework"></a>Basic Detection Framework</h1><h2 id="Two-stage："><a href="#Two-stage：" class="headerlink" title="Two stage："></a>Two stage：</h2><p>[R-CNN]<br>[SPP-Net]<br>[Fast R-CNN]<br>[Faster R-CNN]</p>
<h2 id="One-stage"><a href="#One-stage" class="headerlink" title="One stage:"></a>One stage:</h2><p>[YOLO]<br>[SSD]</p>
<h1 id="Improvement-for-Two-Stage-Framework"><a href="#Improvement-for-Two-Stage-Framework" class="headerlink" title="Improvement for Two Stage Framework"></a>Improvement for Two Stage Framework</h1><h2 id="To-alleviate-the-problems-arising-from-scale-variation-and-small-object-instances"><a href="#To-alleviate-the-problems-arising-from-scale-variation-and-small-object-instances" class="headerlink" title="To alleviate the problems arising from scale variation and small object instances"></a>To alleviate the problems arising from scale variation and small object instances</h2><h3 id="Construct-feature-pyramid"><a href="#Construct-feature-pyramid" class="headerlink" title="Construct feature pyramid"></a>Construct feature pyramid</h3><p><strong>[FPN - CVPR2017]</strong></p>
<h3 id="Multi-scale-training-approach-image-pyramid"><a href="#Multi-scale-training-approach-image-pyramid" class="headerlink" title="Multi-scale training approach (image pyramid)"></a>Multi-scale training approach (image pyramid)</h3><p><strong>[SNIP - CVPR2018] An Analysis of Scale Invariance in Object Detection – SNIP</strong><br>[paper] <a href="https://arxiv.org/abs/1711.08189" target="_blank" rel="noopener">https://arxiv.org/abs/1711.08189</a><br>[summarization]<br>-Scale Normalization for Image Pyramids<br>-Use Image Pyramids, for each image(with multi-scale), training is only performed on objects that fall in the desired scale range and the remainder are simply ignored during back-propagation<br>-Deformable R-FCN + Soft-NMS ResNet-101/DPN-98      -&gt; 48.3mAP<br><img src="/2018/12/14/object_detection_paper_summarization/3.png" alt=""></p>
<p><strong>[SNIPER - NIPS2018] SNIPER: Efficient Multi-Scale Training</strong><br>[paper] <a href="https://arxiv.org/abs/1805.09300" target="_blank" rel="noopener">https://arxiv.org/abs/1805.09300</a><br>[official code] <a href="https://github.com/mahyarnajibi/SNIPER" target="_blank" rel="noopener">https://github.com/mahyarnajibi/SNIPER</a><br>[summarization]<br>-Chip Generation: For each scale, KxK pixels chips are placed at equal intervals of d pixels<br>-Positive Chip Selection: A ground-truth box is said to be covered if it is completely enclosed inside a chip. Ground-truth instances which have a partial overlap (IoU &gt; 0) with a chip are cropped. All the cropped ground-truth boxes (valid or invalid) are retained in the chip<br><img src="/2018/12/14/object_detection_paper_summarization/4.png" alt=""><br>-Negative Chip Selection:First train RPN for a couple of epochs. Then, for each scale i, we greedily select all the chips which cover at least M proposals.<br><img src="/2018/12/14/object_detection_paper_summarization/5.png" alt=""></p>
<h2 id="To-improve-localization-accuracy"><a href="#To-improve-localization-accuracy" class="headerlink" title="To improve localization accuracy"></a>To improve localization accuracy</h2><h3 id="Improve-bounding-box-refinement-method"><a href="#Improve-bounding-box-refinement-method" class="headerlink" title="Improve bounding box refinement method"></a>Improve bounding box refinement method</h3><p>Previous method: Using iterative bounding box regression to refine a bounding box.<br>This idea  ignores two problems:<br>(1) a regressor trained at low IoU threshhold (such as 0.5, used to defind postives/negetives) is suboptimal for proposals of higher IoUs.<br>(2) the distribution of bounding boxes changes significantly after each iteration.<br>Usually, there is no benefit beyond applying the same regressoin function twice.</p>
<p><strong>[Cascade R-CNN]</strong></p>
<p><strong>[IoU-Net]</strong> </p>
<h3 id="Predict-localization-confidence"><a href="#Predict-localization-confidence" class="headerlink" title="Predict localization confidence"></a>Predict localization confidence</h3><p>-Two drawbacks without localization confidence:<br>(1)  In nms, the classification scores are typically used as the metric for ranking the proposals. But the localization accuracy is not well correlated with the classification confidence.<br>(2) The absence of localization confidence makes the widely adopted bounding box regression less interpretable. Bounding box regression may degenerate the localization of input bounding boxes if applied for multiple times</p>
<p><strong>[IoU-Net ECCV2018] Acquisition of Localization Confidence for Accurate Object Detection</strong><br>[paper] <a href="https://arxiv.org/abs/1807.11590" target="_blank" rel="noopener">https://arxiv.org/abs/1807.11590</a><br>[official code] <a href="https://github.com/vacancy/PreciseRoIPooling" target="_blank" rel="noopener">https://github.com/vacancy/PreciseRoIPooling</a> (PreciseRoIPooling)<br>[summarization]<br>-Introduce <em>IoU-Net</em>, which predicts the IoU between detected bounding boxes and their corresponding ground-truth boxes, making the networks aware of the localization criterion.<br>-Generate bounding boxes and labels for training the IoU-Net by augmenting the ground-truth, instead of taking proposals from RPNs.<br><img src="/2018/12/14/object_detection_paper_summarization/11.png" alt=""><br>-<strong><em>IoU-guided NMS</em></strong>: Replace classification confidence with the predicted IoU as the ranking keyword in NMS. When a box i eliminates box j, update the classification confidence si of box i by si = max(si; sj )<br>-<strong><em>New bounding box refinement method</em></strong>:  Optimization-based bounding box refinement (on par with traditional regression-based methods.)<br><img src="/2018/12/14/object_detection_paper_summarization/13.png" alt=""><br>-Precise RoI Pooling: It avoids any quantization of coordinates and has a continuous gradient on bounding box coordinates.<br><img src="/2018/12/14/object_detection_paper_summarization/12.png" alt=""></p>
<h2 id="To-remove-duplicated-bounding-boxes"><a href="#To-remove-duplicated-bounding-boxes" class="headerlink" title="To remove duplicated bounding boxes"></a>To remove duplicated bounding boxes</h2><p>Widely-adopted approach: NMS</p>
<h3 id="Modify-NMS"><a href="#Modify-NMS" class="headerlink" title="Modify NMS"></a>Modify NMS</h3><h2 id="To-eliminate-high-scored-false-positives"><a href="#To-eliminate-high-scored-false-positives" class="headerlink" title="To eliminate high-scored false positives"></a>To eliminate high-scored false positives</h2><p><img src="/2018/12/14/object_detection_paper_summarization/14.png" alt=""></p>
<h3 id="Learning-high-quality-object-detectors"><a href="#Learning-high-quality-object-detectors" class="headerlink" title="Learning high quality object detectors"></a>Learning high quality object detectors</h3><p>-IoU threshhold(u): is set to determine positives/negetives</p>
<p>When u is high, the positives contain less background, but it is difficult to assemble enough positive training examples. When u is low, a richer and more diversified positive training set is available, but the trained detector has little incentive to reject close false positives.In general, it is very difficult to ask a single classifier to perform uniformly well over all IoU levels.</p>
<p>低IoU threshold对于低IoU的样本有更好的改善，但是对于高IoU的样本就不如高threshold的有用。原因在于不同threshold下样本的分布会不一致，也就导致同一个threshold很难对所有样本都有效。<br><img src="/2018/12/14/object_detection_paper_summarization/15.png" alt=""></p>
<p><strong>[Cascade RCNN - CVPR2018] Cascade R-CNN: Delving into High Quality Object Detection</strong><br>[paper] <a href="https://arxiv.org/abs/1712.00726" target="_blank" rel="noopener">https://arxiv.org/abs/1712.00726</a><br>[official code] <a href="https://github.com/zhaoweicai/cascade-rcnn" target="_blank" rel="noopener">https://github.com/zhaoweicai/cascade-rcnn</a><br>[summarization]<br><img src="/2018/12/14/object_detection_paper_summarization/16.png" alt=""><br>-At each stage t, the R-CNN includes a classifier ht and a regressor ft optimized for IoU threshold ut, where ut &gt; ut−1. This is guaranteed by minimizing the loss<br><img src="/2018/12/14/object_detection_paper_summarization/17.png" alt=""><br>-Cascaded regression is a resampling procedure that changes the distribution of hypotheses to be processed by the different stages. By adjusting bounding boxes, each stage aims to find a good set of close false positives for training the next stage<br>-A bounding box regressor trained for a certain u tends to produce bounding boxes of higher IoU. Hence, starting from a set of examples (xi, bi), cascade regression successively resamples an example distribution (x′i, b′i) of higher IoU.<br><img src="/2018/12/14/object_detection_paper_summarization/18.png" alt=""></p>
<h3 id="Improve-the-classification-power"><a href="#Improve-the-classification-power" class="headerlink" title="Improve the classification power"></a>Improve the classification power</h3><p>(1)Shared feature representation for both classification and localization may not be optimal<br>(2)joint optimization also leads to possible sub-optimal to balance the goals of multiple tasks and could not directly utilize the full potential on individual tasks;<br>(3)large receptive fields could lead to inferior classification capacity by introducing redundant context information for small objects.</p>
<p><strong>[DCR - ECCV2018] Revisiting RCNN: On Awakening the Classification Power of Faster RCNN</strong><br>[paper] <a href="https://arxiv.org/abs/1803.06799" target="_blank" rel="noopener">https://arxiv.org/abs/1803.06799</a><br>[official code] <a href="https://github.com/bowenc0221/Decoupled-Classification-Refinement" target="_blank" rel="noopener">https://github.com/bowenc0221/Decoupled-Classification-Refinement</a><br>[summarization]<br>-Propose Decoupled Classification Refinement to eliminate high-scored false positives and improve the region proposal classification results.<br>-It takes input from a base classiffier, e.g. the Faster RCNN, and refine the classification results using a RCNN-styled network.<br>-Adaptive Receptive Field<br><img src="/2018/12/14/object_detection_paper_summarization/1.jpg" alt=""></p>
<p><strong>[DCR V2]  Decoupled Classification Refinement: Hard False Positive Suppression for Object Detection</strong><br><img src="/2018/12/14/object_detection_paper_summarization/2.jpg" alt=""></p>
<h2 id="Anchor"><a href="#Anchor" class="headerlink" title="Anchor"></a>Anchor</h2><p>Anchors are regression references and classification candidates to predict proposals (for two-stage detectors) or final bounding boxes (for single-stage detectors). Modern object detection pipelines usually begin with a large set of densely distributed anchors. </p>
<p>Two general rules for a reasonable anchor design: (1)Alignment: anchor centers need to be well aligned with feature map pixels. (2)Consistency: the receptive field and semantic scope are consistent in different regions of a feature map, so the scale and shape of anchors across different locations should be consistent.</p>
<p>The uniform anchoring scheme can lead to two difficulties: (1) A neat set of anchors of fixed aspect ratios has to be predefined for different problems. A wrong design may hamper the speed and accuracy of the detector. (2) To maintain a sufficiently high recall for proposals, a large number of anchors are needed, while most of them correspond to false candidates that are irrelevant to the object of interests.</p>
<p><strong>[Guided Anchoring - CVPR2019] Region Proposal by Guided Anchoring</strong><br>[paper] <a href="https://arxiv.org/abs/1901.03278" target="_blank" rel="noopener">https://arxiv.org/abs/1901.03278</a><br>[official code] <a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener">https://github.com/open-mmlab/mmdetection</a><br>[summarization]<br><img src="/2018/12/14/object_detection_paper_summarization/19.png" alt=""><br>(1)<em>Anchor Location Prediction</em>:<br>-a 1x1 convolution and an element-wise sigmoid function.<br>-yields a probability map that indicates the possible locations of the objects.<br>-selecting those locations whose corresponding probability values are above a predefined threshold.<br>-use masked convolution when inference<br>-define center/ignore/outside region, use focal loss when training<br>(2)<em>Anchor Shape Prediction</em>:<br>-predict the best shape (w; h) for each location.<br>-a 1x1 convolutional layer that yields a two-channel map that contains the values of dw and dh, an element-wise transform layer that implements Eq.(2).<br>  <img src="/2018/12/14/object_detection_paper_summarization/20.png" alt=""><br>-when training, sample some common values of w and h, calculate the IoU of these sampled anchors with gt, use the maximum. use bounded iou loss.<br>(3)<em>Anchor Guided Feature Adaptation</em><br>-Ideally, the feature for a large anchor should encode the content over a large region, while those for small anchors should have smaller scopes accordingly.<br>-first predict an offset field from the output of anchor shape prediction branch, and then apply 3x3 deformable convolution to the original feature map with the offsets.<br>(4)<em>The Use of High quality Proposals</em><br>-set a higher positive/negative threshold and use fewer samples when training detectors with GA-RPN compared to RPN.</p>
<h2 id="The-way-to-extract-fixed-length-feature-vector"><a href="#The-way-to-extract-fixed-length-feature-vector" class="headerlink" title="The way to extract fixed-length feature vector"></a>The way to extract fixed-length feature vector</h2><p><strong>RoI Pooling</strong> [Fast R-CNN]<br><strong>RoI Align</strong> [Mask R-CNN]<br><strong>Precise RoI Pooling</strong> [IoU-Net]</p>
<h1 id="Improvement-for-One-Stage-Framework"><a href="#Improvement-for-One-Stage-Framework" class="headerlink" title="Improvement for  One Stage Framework"></a>Improvement for  One Stage Framework</h1><h2 id="To-alleviate-the-problems-arising-from-scale-variation-and-small-object-instances-1"><a href="#To-alleviate-the-problems-arising-from-scale-variation-and-small-object-instances-1" class="headerlink" title="To alleviate the problems arising from scale variation and small object instances"></a>To alleviate the problems arising from scale variation and small object instances</h2><h3 id="Construct-feature-pyramid-1"><a href="#Construct-feature-pyramid-1" class="headerlink" title="Construct feature pyramid"></a>Construct feature pyramid</h3><p><strong>[PFPNet - ECCV2018] Parallel Feature Pyramid Network for Object Detection</strong><br>[paper]<br>[summarization]<br>-Employ the SPP module to generate pyramid-shaped feature maps via widening the network width instead of increasing its depth.<br>-SSD / RefineDet  VGG16<br><img src="/2018/12/14/object_detection_paper_summarization/9.png" alt=""><br><img src="/2018/12/14/object_detection_paper_summarization/10.png" alt=""></p>
<p><strong>[M2Det - AAAI2019] M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network</strong><br>[paper] <a href="https://arxiv.org/abs/1811.04533" target="_blank" rel="noopener">https://arxiv.org/abs/1811.04533</a><br>[official code] <a href="https://github.com/qijiezhao/M2Det" target="_blank" rel="noopener">https://github.com/qijiezhao/M2Det</a><br>[summarization]<br>-For previous feature pyramid method, each feature map (used for detecting objects in a specific range of size) in the pyramid mainly or only consists of single-level features will result in suboptimal detection performance.<br>-Multi-Level Feature Pyramid Network (MLFPN).<br>-Based on SSD<br><img src="/2018/12/14/object_detection_paper_summarization/6.png" alt=""><br><img src="/2018/12/14/object_detection_paper_summarization/7.png" alt=""><br><img src="/2018/12/14/object_detection_paper_summarization/8.png" alt=""></p>
<h2 id="Anchor-default-box"><a href="#Anchor-default-box" class="headerlink" title="Anchor(default box)"></a>Anchor(default box)</h2><p>In short, anchor method suggests dividing the box space (including position, size, class, etc.) into discrete bins (not necessarily disjoint) and generating each object box via the anchor function defined in the corresponding bin.</p>
<p>Currently most of the detectors model anchors via enumeration, i.e. predefining a number of anchor boxes with all kinds of positions, sizes and class labels, which leads to the following issues.First, anchor boxes need careful design (chosen by handcraft or statistical methods like clustering). Second, predefined anchor functions may cause too many parameters.</p>
<p><strong>[MetaAnchor - NIPS2018] MetaAnchor: Learning to Detect Objects with Customized Anchor</strong><br>[paper] <a href="https://arxiv.org/abs/1807.00980" target="_blank" rel="noopener">https://arxiv.org/abs/1807.00980</a><br>[summarization]</p>
<h1 id="Other-improvement"><a href="#Other-improvement" class="headerlink" title="Other improvement"></a>Other improvement</h1>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/14/network_structure_experience/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Sicheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Good Good Study">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/14/network_structure_experience/" itemprop="url">Experience in Network Structure</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-14T14:36:12+08:00">
                2018-12-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Improvement-for-Feature-Expression"><a href="#Improvement-for-Feature-Expression" class="headerlink" title="Improvement for Feature Expression"></a>Improvement for Feature Expression</h1><h2 id="inverted-residual-with-linear-bottleneck"><a href="#inverted-residual-with-linear-bottleneck" class="headerlink" title="inverted residual with linear bottleneck"></a>inverted residual with linear bottleneck</h2><h2 id="ReLU6-、-ReLU、PReLU"><a href="#ReLU6-、-ReLU、PReLU" class="headerlink" title="ReLU6 、 ReLU、PReLU"></a>ReLU6 、 ReLU、PReLU</h2><h1 id="Acceleration-and-Compression"><a href="#Acceleration-and-Compression" class="headerlink" title="Acceleration and Compression"></a>Acceleration and Compression</h1><h2 id="Depthwise-Separable-Convolution"><a href="#Depthwise-Separable-Convolution" class="headerlink" title="Depthwise Separable Convolution"></a>Depthwise Separable Convolution</h2><p><img src="/2018/12/14/network_structure_experience/2.jpg" alt=""></p>
<p>computational cost reduce from </p>
<p><img src="/2018/12/14/network_structure_experience/3.jpg" alt=""></p>
<p>to</p>
<p><img src="/2018/12/14/network_structure_experience/4.jpg" alt=""></p>
<h2 id="Group-Convolution"><a href="#Group-Convolution" class="headerlink" title="Group Convolution"></a>Group Convolution</h2><h2 id="from-35x35x320-to-17x17x640"><a href="#from-35x35x320-to-17x17x640" class="headerlink" title="from 35x35x320 to 17x17x640:"></a>from 35x35x320 to 17x17x640:</h2><ol>
<li>conv+pooling or pooling + conv</li>
<li>conv with stride 2</li>
<li><img src="/2018/12/14/network_structure_experience/1.png" alt=""><br>remain to study which is faster between 2 and 3.</li>
</ol>
<h1 id="Inspired-Architecture"><a href="#Inspired-Architecture" class="headerlink" title="Inspired Architecture"></a>Inspired Architecture</h1><h1 id="Insight"><a href="#Insight" class="headerlink" title="Insight"></a>Insight</h1><p>Manifold of interest should lie in a low-dimensional subspace of the higher-dimensional activation space (non-linearity destroys information in low-dimensional space.)<br><img src="/2018/12/14/network_structure_experience/5.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Pan Sicheng</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Pan Sicheng</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
